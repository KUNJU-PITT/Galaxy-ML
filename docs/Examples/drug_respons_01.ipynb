{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pprint\n",
    "import skrebate\n",
    "import imblearn\n",
    "import time\n",
    "from imblearn import under_sampling, over_sampling, combine\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "from sklearn import (preprocessing, svm, linear_model, ensemble, naive_bayes,\n",
    "                    tree, neighbors, decomposition, kernel_approximation, cluster)\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.model_selection import (KFold, GroupKFold, StratifiedKFold,\n",
    "                                    LeaveOneGroupOut, cross_validate,\n",
    "                                    cross_val_predict, learning_curve, GridSearchCV)\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, SelectFromModel, VarianceThreshold, f_classif\n",
    "from sklearn.metrics import r2_score, auc, roc_auc_score, balanced_accuracy_score, confusion_matrix, roc_curve\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import QuantileTransformer, quantile_transform\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.regressor import StackingCVRegressor, StackingRegressor\n",
    "from mlxtend.classifier import StackingCVClassifier, StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Galaxy_ML = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "\n",
    "sys.path.append(os.path.join(Galaxy_ML, 'galaxy_ml'))\n",
    "try:\n",
    "    from iraps_classifier import BinarizeTargetClassifier, BinarizeTargetRegressor\n",
    "except ImportError:\n",
    "    raise ImportError(\"galaxy_ml is not in path!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.call('pip freeze', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depmap_ID</th>\n",
       "      <th>DRUG_ID</th>\n",
       "      <th>DRUG_NAME</th>\n",
       "      <th>Primary Disease</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AUC</th>\n",
       "      <th>TSPAN6 (ENSG00000000003)</th>\n",
       "      <th>TNMD (ENSG00000000005)</th>\n",
       "      <th>DPM1 (ENSG00000000419)</th>\n",
       "      <th>SCYL3 (ENSG00000000457)</th>\n",
       "      <th>...</th>\n",
       "      <th>NUDT3 (ENSG00000272325)</th>\n",
       "      <th>C6ORF165 (ENSG00000272514)</th>\n",
       "      <th>MUSTN1 (ENSG00000272573)</th>\n",
       "      <th>DOC2B (ENSG00000272636)</th>\n",
       "      <th>RP11-309L24.9 (ENSG00000272899)</th>\n",
       "      <th>C2ORF15 (ENSG00000273045)</th>\n",
       "      <th>GRIN2B (ENSG00000273079)</th>\n",
       "      <th>SNURF (ENSG00000273173)</th>\n",
       "      <th>RP11-1263C18.1 (ENSG00000273238)</th>\n",
       "      <th>ZBTB8B (ENSG00000273274)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ACH-000087</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Bone Cancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.846324</td>\n",
       "      <td>4.955127</td>\n",
       "      <td>0.070389</td>\n",
       "      <td>5.873567</td>\n",
       "      <td>2.853996</td>\n",
       "      <td>...</td>\n",
       "      <td>4.694880</td>\n",
       "      <td>0.137504</td>\n",
       "      <td>0.545968</td>\n",
       "      <td>3.203201</td>\n",
       "      <td>0.978196</td>\n",
       "      <td>0.669027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.092229</td>\n",
       "      <td>0.669027</td>\n",
       "      <td>0.042644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACH-000327</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Lung Cancer</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.970014</td>\n",
       "      <td>4.041769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.813525</td>\n",
       "      <td>1.918386</td>\n",
       "      <td>...</td>\n",
       "      <td>3.730096</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>0.070389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.035624</td>\n",
       "      <td>2.310340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.641546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACH-000905</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Bladder Cancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.915457</td>\n",
       "      <td>5.881175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.643135</td>\n",
       "      <td>2.039138</td>\n",
       "      <td>...</td>\n",
       "      <td>2.664483</td>\n",
       "      <td>0.084064</td>\n",
       "      <td>0.226509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.422233</td>\n",
       "      <td>2.003602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.660210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.432959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ACH-000242</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Bladder Cancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.987345</td>\n",
       "      <td>7.496574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.458940</td>\n",
       "      <td>2.364572</td>\n",
       "      <td>...</td>\n",
       "      <td>3.658783</td>\n",
       "      <td>0.739848</td>\n",
       "      <td>0.201634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.378512</td>\n",
       "      <td>3.557042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.843607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.948601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ACH-000384</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Bladder Cancer</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.952230</td>\n",
       "      <td>5.755155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.928844</td>\n",
       "      <td>2.895303</td>\n",
       "      <td>...</td>\n",
       "      <td>3.324811</td>\n",
       "      <td>2.042644</td>\n",
       "      <td>1.531069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.622930</td>\n",
       "      <td>3.244887</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.405312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.077243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ACH-000323</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Brain Cancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.922807</td>\n",
       "      <td>4.590362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.647890</td>\n",
       "      <td>1.899176</td>\n",
       "      <td>...</td>\n",
       "      <td>3.187451</td>\n",
       "      <td>0.111031</td>\n",
       "      <td>0.526069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.298658</td>\n",
       "      <td>0.176323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.463524</td>\n",
       "      <td>0.650765</td>\n",
       "      <td>0.014355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ACH-000137</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Brain Cancer</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.901520</td>\n",
       "      <td>5.108106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.888500</td>\n",
       "      <td>2.207893</td>\n",
       "      <td>...</td>\n",
       "      <td>3.861955</td>\n",
       "      <td>0.137504</td>\n",
       "      <td>0.879706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333424</td>\n",
       "      <td>1.490570</td>\n",
       "      <td>0.056584</td>\n",
       "      <td>7.145372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.757023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ACH-000738</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Brain Cancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.901069</td>\n",
       "      <td>4.078951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.691953</td>\n",
       "      <td>2.121015</td>\n",
       "      <td>...</td>\n",
       "      <td>3.056584</td>\n",
       "      <td>0.084064</td>\n",
       "      <td>0.855990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.536053</td>\n",
       "      <td>0.505891</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>6.101818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.704872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ACH-000571</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Brain Cancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.960333</td>\n",
       "      <td>3.408712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.677931</td>\n",
       "      <td>2.269033</td>\n",
       "      <td>...</td>\n",
       "      <td>3.247928</td>\n",
       "      <td>0.124328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.731183</td>\n",
       "      <td>0.495695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.669027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ACH-000040</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Brain Cancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.983662</td>\n",
       "      <td>3.828835</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.436295</td>\n",
       "      <td>2.073820</td>\n",
       "      <td>...</td>\n",
       "      <td>3.782409</td>\n",
       "      <td>0.526069</td>\n",
       "      <td>0.516015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.021480</td>\n",
       "      <td>0.687061</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>6.302685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ACH-000075</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Brain Cancer</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.966786</td>\n",
       "      <td>3.842979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.075319</td>\n",
       "      <td>1.963474</td>\n",
       "      <td>...</td>\n",
       "      <td>2.378512</td>\n",
       "      <td>0.400538</td>\n",
       "      <td>0.214125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.839960</td>\n",
       "      <td>0.286881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.239551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ACH-000570</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Brain Cancer</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.927201</td>\n",
       "      <td>5.956057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.783064</td>\n",
       "      <td>2.788686</td>\n",
       "      <td>...</td>\n",
       "      <td>3.589763</td>\n",
       "      <td>0.443607</td>\n",
       "      <td>1.084064</td>\n",
       "      <td>0.070389</td>\n",
       "      <td>1.664483</td>\n",
       "      <td>0.823749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.531459</td>\n",
       "      <td>0.111031</td>\n",
       "      <td>0.056584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ACH-000392</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Lung Cancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.979913</td>\n",
       "      <td>5.791814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.374170</td>\n",
       "      <td>2.695994</td>\n",
       "      <td>...</td>\n",
       "      <td>3.560715</td>\n",
       "      <td>0.056584</td>\n",
       "      <td>0.422233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250962</td>\n",
       "      <td>2.211012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ACH-000662</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Lung Cancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.963470</td>\n",
       "      <td>5.733083</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>6.925999</td>\n",
       "      <td>1.871844</td>\n",
       "      <td>...</td>\n",
       "      <td>3.137504</td>\n",
       "      <td>0.150560</td>\n",
       "      <td>0.321928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111031</td>\n",
       "      <td>2.408712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.715893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ACH-000769</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Lung Cancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.988805</td>\n",
       "      <td>5.450551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.140370</td>\n",
       "      <td>2.469886</td>\n",
       "      <td>...</td>\n",
       "      <td>3.723559</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.201634</td>\n",
       "      <td>0.042644</td>\n",
       "      <td>0.695994</td>\n",
       "      <td>3.264536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.594698</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ACH-000589</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Lung Cancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.981728</td>\n",
       "      <td>5.039577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.544733</td>\n",
       "      <td>2.704872</td>\n",
       "      <td>...</td>\n",
       "      <td>3.003602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.169925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238787</td>\n",
       "      <td>1.823749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.014355</td>\n",
       "      <td>0.097611</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ACH-000744</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Lung Cancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.984961</td>\n",
       "      <td>3.303050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.725196</td>\n",
       "      <td>2.735522</td>\n",
       "      <td>...</td>\n",
       "      <td>3.058316</td>\n",
       "      <td>0.895303</td>\n",
       "      <td>2.526069</td>\n",
       "      <td>0.042644</td>\n",
       "      <td>1.500802</td>\n",
       "      <td>1.356144</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>5.731455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ACH-000766</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Lung Cancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.984860</td>\n",
       "      <td>5.660495</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>6.713833</td>\n",
       "      <td>2.257011</td>\n",
       "      <td>...</td>\n",
       "      <td>2.446256</td>\n",
       "      <td>0.070389</td>\n",
       "      <td>0.298658</td>\n",
       "      <td>0.389567</td>\n",
       "      <td>1.169925</td>\n",
       "      <td>2.992768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ACH-000021</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Lung Cancer</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.898666</td>\n",
       "      <td>4.856488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.518850</td>\n",
       "      <td>2.375735</td>\n",
       "      <td>...</td>\n",
       "      <td>3.494416</td>\n",
       "      <td>0.495695</td>\n",
       "      <td>0.321928</td>\n",
       "      <td>0.056584</td>\n",
       "      <td>0.214125</td>\n",
       "      <td>1.867896</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>7.179909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ACH-000733</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Lung Cancer</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.986679</td>\n",
       "      <td>4.900625</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>5.840715</td>\n",
       "      <td>1.871844</td>\n",
       "      <td>...</td>\n",
       "      <td>3.099295</td>\n",
       "      <td>0.226509</td>\n",
       "      <td>0.176323</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>0.389567</td>\n",
       "      <td>3.280956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.389567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ACH-000951</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Lung Cancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.986086</td>\n",
       "      <td>4.716991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.276124</td>\n",
       "      <td>2.582556</td>\n",
       "      <td>...</td>\n",
       "      <td>3.735522</td>\n",
       "      <td>1.042644</td>\n",
       "      <td>0.163499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097611</td>\n",
       "      <td>2.378512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.594549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ACH-000875</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Lung Cancer</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.965271</td>\n",
       "      <td>5.975676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.923862</td>\n",
       "      <td>2.443607</td>\n",
       "      <td>...</td>\n",
       "      <td>3.496974</td>\n",
       "      <td>0.070389</td>\n",
       "      <td>0.137504</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>0.555816</td>\n",
       "      <td>1.327687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.479619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ACH-000121</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Lung Cancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.982635</td>\n",
       "      <td>4.646163</td>\n",
       "      <td>0.097611</td>\n",
       "      <td>6.660353</td>\n",
       "      <td>2.286881</td>\n",
       "      <td>...</td>\n",
       "      <td>3.690417</td>\n",
       "      <td>1.570463</td>\n",
       "      <td>0.214125</td>\n",
       "      <td>2.070389</td>\n",
       "      <td>0.389567</td>\n",
       "      <td>0.555816</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>6.827311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ACH-000853</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Lung Cancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.979830</td>\n",
       "      <td>4.660495</td>\n",
       "      <td>0.042644</td>\n",
       "      <td>6.873444</td>\n",
       "      <td>1.879706</td>\n",
       "      <td>...</td>\n",
       "      <td>3.620586</td>\n",
       "      <td>1.339137</td>\n",
       "      <td>1.250962</td>\n",
       "      <td>0.918386</td>\n",
       "      <td>0.485427</td>\n",
       "      <td>0.695994</td>\n",
       "      <td>0.111031</td>\n",
       "      <td>6.529821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.815575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ACH-000530</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Lung Cancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.978489</td>\n",
       "      <td>5.358607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.094078</td>\n",
       "      <td>2.545968</td>\n",
       "      <td>...</td>\n",
       "      <td>5.468583</td>\n",
       "      <td>2.771886</td>\n",
       "      <td>0.536053</td>\n",
       "      <td>2.767655</td>\n",
       "      <td>0.925999</td>\n",
       "      <td>0.807355</td>\n",
       "      <td>1.807355</td>\n",
       "      <td>7.774524</td>\n",
       "      <td>1.570463</td>\n",
       "      <td>1.422233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ACH-000749</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Lung Cancer</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.947174</td>\n",
       "      <td>4.684258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.079805</td>\n",
       "      <td>1.735522</td>\n",
       "      <td>...</td>\n",
       "      <td>3.953265</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.839960</td>\n",
       "      <td>0.475085</td>\n",
       "      <td>0.613532</td>\n",
       "      <td>0.933573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.227857</td>\n",
       "      <td>0.443607</td>\n",
       "      <td>0.150560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ACH-000866</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Lung Cancer</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.909941</td>\n",
       "      <td>5.881420</td>\n",
       "      <td>0.056584</td>\n",
       "      <td>5.801935</td>\n",
       "      <td>3.381283</td>\n",
       "      <td>...</td>\n",
       "      <td>4.072963</td>\n",
       "      <td>0.622930</td>\n",
       "      <td>1.097611</td>\n",
       "      <td>0.111031</td>\n",
       "      <td>0.565597</td>\n",
       "      <td>2.472488</td>\n",
       "      <td>0.124328</td>\n",
       "      <td>7.428863</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.117695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ACH-000514</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Lung Cancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.977466</td>\n",
       "      <td>4.905447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.751678</td>\n",
       "      <td>2.965323</td>\n",
       "      <td>...</td>\n",
       "      <td>4.350497</td>\n",
       "      <td>0.622930</td>\n",
       "      <td>0.650765</td>\n",
       "      <td>1.298658</td>\n",
       "      <td>1.827819</td>\n",
       "      <td>3.505891</td>\n",
       "      <td>0.286881</td>\n",
       "      <td>0.097611</td>\n",
       "      <td>1.510962</td>\n",
       "      <td>2.375735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ACH-000431</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Lung Cancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.987780</td>\n",
       "      <td>5.503031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.088735</td>\n",
       "      <td>2.731183</td>\n",
       "      <td>...</td>\n",
       "      <td>4.934988</td>\n",
       "      <td>0.163499</td>\n",
       "      <td>2.558268</td>\n",
       "      <td>3.017922</td>\n",
       "      <td>1.028569</td>\n",
       "      <td>0.948601</td>\n",
       "      <td>0.454176</td>\n",
       "      <td>7.614195</td>\n",
       "      <td>0.238787</td>\n",
       "      <td>1.090853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ACH-000729</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Lung Cancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.991654</td>\n",
       "      <td>5.767655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.167318</td>\n",
       "      <td>3.095924</td>\n",
       "      <td>...</td>\n",
       "      <td>5.075533</td>\n",
       "      <td>0.505891</td>\n",
       "      <td>0.454176</td>\n",
       "      <td>0.137504</td>\n",
       "      <td>1.137504</td>\n",
       "      <td>4.237258</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>7.693905</td>\n",
       "      <td>2.788686</td>\n",
       "      <td>1.761285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>ACH-000287</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Lymphoma</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.961092</td>\n",
       "      <td>0.097611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.028790</td>\n",
       "      <td>2.757023</td>\n",
       "      <td>...</td>\n",
       "      <td>3.416840</td>\n",
       "      <td>0.250962</td>\n",
       "      <td>0.879706</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>1.070389</td>\n",
       "      <td>0.941106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.710531</td>\n",
       "      <td>0.084064</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>ACH-000065</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Leukemia</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.961127</td>\n",
       "      <td>0.275007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.451211</td>\n",
       "      <td>2.889474</td>\n",
       "      <td>...</td>\n",
       "      <td>4.112700</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.286881</td>\n",
       "      <td>0.604071</td>\n",
       "      <td>0.226509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.780310</td>\n",
       "      <td>0.298658</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>ACH-000124</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Lymphoma</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.881394</td>\n",
       "      <td>0.042644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.048323</td>\n",
       "      <td>1.847997</td>\n",
       "      <td>...</td>\n",
       "      <td>4.162693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189034</td>\n",
       "      <td>0.695994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.224773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>ACH-000751</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Leukemia</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.992637</td>\n",
       "      <td>1.238787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.520108</td>\n",
       "      <td>2.411426</td>\n",
       "      <td>...</td>\n",
       "      <td>3.758090</td>\n",
       "      <td>0.042644</td>\n",
       "      <td>1.182692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.505891</td>\n",
       "      <td>0.176323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.548128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>ACH-000218</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Leukemia</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.982835</td>\n",
       "      <td>0.124328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.638364</td>\n",
       "      <td>2.339137</td>\n",
       "      <td>...</td>\n",
       "      <td>4.899659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226509</td>\n",
       "      <td>0.516015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.473787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>ACH-000922</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Leukemia</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.867959</td>\n",
       "      <td>0.097611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.425258</td>\n",
       "      <td>2.235727</td>\n",
       "      <td>...</td>\n",
       "      <td>4.223423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124328</td>\n",
       "      <td>0.214125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.093919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>ACH-000365</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Lymphoma</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.997365</td>\n",
       "      <td>0.124328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.057017</td>\n",
       "      <td>2.025029</td>\n",
       "      <td>...</td>\n",
       "      <td>4.266787</td>\n",
       "      <td>0.124328</td>\n",
       "      <td>1.570463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.505891</td>\n",
       "      <td>1.622930</td>\n",
       "      <td>0.097611</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>ACH-000660</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Lymphoma</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.883126</td>\n",
       "      <td>0.536053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.628044</td>\n",
       "      <td>2.664483</td>\n",
       "      <td>...</td>\n",
       "      <td>4.304511</td>\n",
       "      <td>0.400538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.400538</td>\n",
       "      <td>1.137504</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>4.929318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>ACH-000611</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Lymphoma</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.995314</td>\n",
       "      <td>0.214125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.990501</td>\n",
       "      <td>2.815575</td>\n",
       "      <td>...</td>\n",
       "      <td>5.516330</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.765535</td>\n",
       "      <td>2.266037</td>\n",
       "      <td>0.042644</td>\n",
       "      <td>6.338068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>ACH-000226</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Lymphoma</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.892946</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.013462</td>\n",
       "      <td>3.744161</td>\n",
       "      <td>...</td>\n",
       "      <td>3.282440</td>\n",
       "      <td>0.443607</td>\n",
       "      <td>0.695994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.028569</td>\n",
       "      <td>1.316146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>ACH-000534</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Lymphoma</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.985744</td>\n",
       "      <td>0.799087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.416502</td>\n",
       "      <td>2.722466</td>\n",
       "      <td>...</td>\n",
       "      <td>4.095080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.384050</td>\n",
       "      <td>0.042644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.942984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.064797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>ACH-001550</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Skin Cancer</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.992005</td>\n",
       "      <td>5.209453</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>7.189330</td>\n",
       "      <td>2.726831</td>\n",
       "      <td>...</td>\n",
       "      <td>3.507160</td>\n",
       "      <td>0.475085</td>\n",
       "      <td>0.454176</td>\n",
       "      <td>0.084064</td>\n",
       "      <td>0.250962</td>\n",
       "      <td>1.056584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.718636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>ACH-000132</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Ovarian Cancer</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.975499</td>\n",
       "      <td>6.532629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.397461</td>\n",
       "      <td>2.666757</td>\n",
       "      <td>...</td>\n",
       "      <td>2.737687</td>\n",
       "      <td>1.669027</td>\n",
       "      <td>0.516015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189034</td>\n",
       "      <td>3.070389</td>\n",
       "      <td>0.250962</td>\n",
       "      <td>4.205549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>ACH-000584</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Ovarian Cancer</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.979747</td>\n",
       "      <td>4.933573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.876394</td>\n",
       "      <td>2.467279</td>\n",
       "      <td>...</td>\n",
       "      <td>3.650765</td>\n",
       "      <td>2.014355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238787</td>\n",
       "      <td>0.084064</td>\n",
       "      <td>3.808385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.652773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.378512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>ACH-000688</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Ovarian Cancer</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.870613</td>\n",
       "      <td>3.280956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.034304</td>\n",
       "      <td>1.589763</td>\n",
       "      <td>...</td>\n",
       "      <td>3.476382</td>\n",
       "      <td>0.097611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163499</td>\n",
       "      <td>0.056584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.233044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>ACH-001373</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Ovarian Cancer</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.977301</td>\n",
       "      <td>4.519164</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>7.469886</td>\n",
       "      <td>2.014355</td>\n",
       "      <td>...</td>\n",
       "      <td>2.250962</td>\n",
       "      <td>0.189034</td>\n",
       "      <td>0.137504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.604071</td>\n",
       "      <td>2.217231</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.042644</td>\n",
       "      <td>0.056584</td>\n",
       "      <td>0.622930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>ACH-000091</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Ovarian Cancer</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.968143</td>\n",
       "      <td>2.803227</td>\n",
       "      <td>0.070389</td>\n",
       "      <td>6.342875</td>\n",
       "      <td>2.021480</td>\n",
       "      <td>...</td>\n",
       "      <td>2.920293</td>\n",
       "      <td>0.250962</td>\n",
       "      <td>0.879706</td>\n",
       "      <td>0.632268</td>\n",
       "      <td>0.214125</td>\n",
       "      <td>0.378512</td>\n",
       "      <td>0.389567</td>\n",
       "      <td>7.059615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.536053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>ACH-000947</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Ovarian Cancer</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.857144</td>\n",
       "      <td>4.006298</td>\n",
       "      <td>0.176323</td>\n",
       "      <td>5.995485</td>\n",
       "      <td>2.589763</td>\n",
       "      <td>...</td>\n",
       "      <td>4.030336</td>\n",
       "      <td>0.226509</td>\n",
       "      <td>0.097611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.124328</td>\n",
       "      <td>1.298658</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>7.577580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>ACH-001500</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Esophageal Cancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.974048</td>\n",
       "      <td>0.731183</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>7.058316</td>\n",
       "      <td>2.680324</td>\n",
       "      <td>...</td>\n",
       "      <td>4.191405</td>\n",
       "      <td>1.077243</td>\n",
       "      <td>0.526069</td>\n",
       "      <td>2.253989</td>\n",
       "      <td>0.432959</td>\n",
       "      <td>0.389567</td>\n",
       "      <td>0.250962</td>\n",
       "      <td>0.321928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>ACH-001368</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Esophageal Cancer</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.985873</td>\n",
       "      <td>3.823749</td>\n",
       "      <td>0.097611</td>\n",
       "      <td>7.425510</td>\n",
       "      <td>1.790772</td>\n",
       "      <td>...</td>\n",
       "      <td>3.295723</td>\n",
       "      <td>0.286881</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111031</td>\n",
       "      <td>0.516015</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>ACH-001654</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Esophageal Cancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.959242</td>\n",
       "      <td>5.340918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.235248</td>\n",
       "      <td>2.659925</td>\n",
       "      <td>...</td>\n",
       "      <td>2.367371</td>\n",
       "      <td>0.454176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.298658</td>\n",
       "      <td>0.536053</td>\n",
       "      <td>2.070389</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>0.150560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>ACH-001496</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Esophageal Cancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.989116</td>\n",
       "      <td>5.364572</td>\n",
       "      <td>0.042644</td>\n",
       "      <td>7.337444</td>\n",
       "      <td>2.833902</td>\n",
       "      <td>...</td>\n",
       "      <td>3.508429</td>\n",
       "      <td>0.226509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.443607</td>\n",
       "      <td>0.632268</td>\n",
       "      <td>3.440952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>ACH-000917</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Esophageal Cancer</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.987574</td>\n",
       "      <td>4.682573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.667892</td>\n",
       "      <td>3.285402</td>\n",
       "      <td>...</td>\n",
       "      <td>3.397803</td>\n",
       "      <td>0.485427</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333424</td>\n",
       "      <td>4.519793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>ACH-000714</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Myeloma</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.966985</td>\n",
       "      <td>0.137504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.451211</td>\n",
       "      <td>3.261531</td>\n",
       "      <td>...</td>\n",
       "      <td>3.760221</td>\n",
       "      <td>0.389567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.316146</td>\n",
       "      <td>0.622930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.961623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>ACH-000763</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Myeloma</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.984661</td>\n",
       "      <td>0.176323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.665904</td>\n",
       "      <td>3.129283</td>\n",
       "      <td>...</td>\n",
       "      <td>3.863938</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>0.111031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.316146</td>\n",
       "      <td>1.967169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.111657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>ACH-000195</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Leukemia</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.983232</td>\n",
       "      <td>2.422233</td>\n",
       "      <td>0.137504</td>\n",
       "      <td>5.987548</td>\n",
       "      <td>2.229588</td>\n",
       "      <td>...</td>\n",
       "      <td>4.268285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226509</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>0.933573</td>\n",
       "      <td>1.014355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.789729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>ACH-000955</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Colon/Colorectal Cancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.949313</td>\n",
       "      <td>5.391974</td>\n",
       "      <td>0.286881</td>\n",
       "      <td>5.888987</td>\n",
       "      <td>4.028569</td>\n",
       "      <td>...</td>\n",
       "      <td>3.674687</td>\n",
       "      <td>0.422233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790772</td>\n",
       "      <td>0.495695</td>\n",
       "      <td>3.063503</td>\n",
       "      <td>0.238787</td>\n",
       "      <td>6.004501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>ACH-000532</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Colon/Colorectal Cancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.947596</td>\n",
       "      <td>4.661636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.648034</td>\n",
       "      <td>2.910733</td>\n",
       "      <td>...</td>\n",
       "      <td>2.553361</td>\n",
       "      <td>0.042644</td>\n",
       "      <td>0.201634</td>\n",
       "      <td>0.111031</td>\n",
       "      <td>0.536053</td>\n",
       "      <td>2.130931</td>\n",
       "      <td>0.056584</td>\n",
       "      <td>0.238787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>ACH-000991</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Colon/Colorectal Cancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.964075</td>\n",
       "      <td>4.186659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.263410</td>\n",
       "      <td>3.599318</td>\n",
       "      <td>...</td>\n",
       "      <td>4.546586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.811471</td>\n",
       "      <td>3.231125</td>\n",
       "      <td>0.948601</td>\n",
       "      <td>1.063503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>ACH-000970</td>\n",
       "      <td>1017</td>\n",
       "      <td>Olaparib</td>\n",
       "      <td>Colon/Colorectal Cancer</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.981441</td>\n",
       "      <td>4.378512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.340206</td>\n",
       "      <td>2.589763</td>\n",
       "      <td>...</td>\n",
       "      <td>3.850999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.422233</td>\n",
       "      <td>1.169925</td>\n",
       "      <td>3.220330</td>\n",
       "      <td>0.124328</td>\n",
       "      <td>0.963474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>515 rows × 18826 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      depmap_ID  DRUG_ID DRUG_NAME          Primary Disease  Gender       AUC  \\\n",
       "5    ACH-000087     1017  Olaparib              Bone Cancer    Male  0.846324   \n",
       "6    ACH-000327     1017  Olaparib              Lung Cancer  Female  0.970014   \n",
       "7    ACH-000905     1017  Olaparib           Bladder Cancer    Male  0.915457   \n",
       "8    ACH-000242     1017  Olaparib           Bladder Cancer    Male  0.987345   \n",
       "9    ACH-000384     1017  Olaparib           Bladder Cancer  Female  0.952230   \n",
       "13   ACH-000323     1017  Olaparib             Brain Cancer    Male  0.922807   \n",
       "14   ACH-000137     1017  Olaparib             Brain Cancer  Female  0.901520   \n",
       "15   ACH-000738     1017  Olaparib             Brain Cancer    Male  0.901069   \n",
       "16   ACH-000571     1017  Olaparib             Brain Cancer    Male  0.960333   \n",
       "17   ACH-000040     1017  Olaparib             Brain Cancer    Male  0.983662   \n",
       "18   ACH-000075     1017  Olaparib             Brain Cancer  Female  0.966786   \n",
       "19   ACH-000570     1017  Olaparib             Brain Cancer  Female  0.927201   \n",
       "21   ACH-000392     1017  Olaparib              Lung Cancer    Male  0.979913   \n",
       "22   ACH-000662     1017  Olaparib              Lung Cancer    Male  0.963470   \n",
       "23   ACH-000769     1017  Olaparib              Lung Cancer    Male  0.988805   \n",
       "24   ACH-000589     1017  Olaparib              Lung Cancer    Male  0.981728   \n",
       "25   ACH-000744     1017  Olaparib              Lung Cancer    Male  0.984961   \n",
       "26   ACH-000766     1017  Olaparib              Lung Cancer    Male  0.984860   \n",
       "27   ACH-000021     1017  Olaparib              Lung Cancer  Female  0.898666   \n",
       "29   ACH-000733     1017  Olaparib              Lung Cancer  Female  0.986679   \n",
       "30   ACH-000951     1017  Olaparib              Lung Cancer    Male  0.986086   \n",
       "31   ACH-000875     1017  Olaparib              Lung Cancer  Female  0.965271   \n",
       "32   ACH-000121     1017  Olaparib              Lung Cancer    Male  0.982635   \n",
       "33   ACH-000853     1017  Olaparib              Lung Cancer    Male  0.979830   \n",
       "34   ACH-000530     1017  Olaparib              Lung Cancer    Male  0.978489   \n",
       "35   ACH-000749     1017  Olaparib              Lung Cancer  Female  0.947174   \n",
       "36   ACH-000866     1017  Olaparib              Lung Cancer  Female  0.909941   \n",
       "37   ACH-000514     1017  Olaparib              Lung Cancer    Male  0.977466   \n",
       "39   ACH-000431     1017  Olaparib              Lung Cancer    Male  0.987780   \n",
       "41   ACH-000729     1017  Olaparib              Lung Cancer    Male  0.991654   \n",
       "..          ...      ...       ...                      ...     ...       ...   \n",
       "780  ACH-000287     1017  Olaparib                 Lymphoma    Male  0.961092   \n",
       "781  ACH-000065     1017  Olaparib                 Leukemia    Male  0.961127   \n",
       "782  ACH-000124     1017  Olaparib                 Lymphoma  Female  0.881394   \n",
       "783  ACH-000751     1017  Olaparib                 Leukemia      -1  0.992637   \n",
       "785  ACH-000218     1017  Olaparib                 Leukemia    Male  0.982835   \n",
       "787  ACH-000922     1017  Olaparib                 Leukemia  Female  0.867959   \n",
       "791  ACH-000365     1017  Olaparib                 Lymphoma    Male  0.997365   \n",
       "792  ACH-000660     1017  Olaparib                 Lymphoma  Female  0.883126   \n",
       "793  ACH-000611     1017  Olaparib                 Lymphoma    Male  0.995314   \n",
       "795  ACH-000226     1017  Olaparib                 Lymphoma  Female  0.892946   \n",
       "799  ACH-000534     1017  Olaparib                 Lymphoma    Male  0.985744   \n",
       "800  ACH-001550     1017  Olaparib              Skin Cancer  Female  0.992005   \n",
       "803  ACH-000132     1017  Olaparib           Ovarian Cancer  Female  0.975499   \n",
       "805  ACH-000584     1017  Olaparib           Ovarian Cancer  Female  0.979747   \n",
       "806  ACH-000688     1017  Olaparib           Ovarian Cancer  Female  0.870613   \n",
       "807  ACH-001373     1017  Olaparib           Ovarian Cancer  Female  0.977301   \n",
       "808  ACH-000091     1017  Olaparib           Ovarian Cancer  Female  0.968143   \n",
       "811  ACH-000947     1017  Olaparib           Ovarian Cancer  Female  0.857144   \n",
       "814  ACH-001500     1017  Olaparib        Esophageal Cancer    Male  0.974048   \n",
       "816  ACH-001368     1017  Olaparib        Esophageal Cancer  Female  0.985873   \n",
       "818  ACH-001654     1017  Olaparib        Esophageal Cancer    Male  0.959242   \n",
       "819  ACH-001496     1017  Olaparib        Esophageal Cancer    Male  0.989116   \n",
       "824  ACH-000917     1017  Olaparib        Esophageal Cancer  Female  0.987574   \n",
       "833  ACH-000714     1017  Olaparib                  Myeloma  Female  0.966985   \n",
       "834  ACH-000763     1017  Olaparib                  Myeloma  Female  0.984661   \n",
       "836  ACH-000195     1017  Olaparib                 Leukemia  Female  0.983232   \n",
       "837  ACH-000955     1017  Olaparib  Colon/Colorectal Cancer    Male  0.949313   \n",
       "838  ACH-000532     1017  Olaparib  Colon/Colorectal Cancer    Male  0.947596   \n",
       "839  ACH-000991     1017  Olaparib  Colon/Colorectal Cancer    Male  0.964075   \n",
       "840  ACH-000970     1017  Olaparib  Colon/Colorectal Cancer  Female  0.981441   \n",
       "\n",
       "     TSPAN6 (ENSG00000000003)  TNMD (ENSG00000000005)  DPM1 (ENSG00000000419)  \\\n",
       "5                    4.955127                0.070389                5.873567   \n",
       "6                    4.041769                0.000000                5.813525   \n",
       "7                    5.881175                0.000000                6.643135   \n",
       "8                    7.496574                0.000000                6.458940   \n",
       "9                    5.755155                0.000000                6.928844   \n",
       "13                   4.590362                0.000000                6.647890   \n",
       "14                   5.108106                0.000000                6.888500   \n",
       "15                   4.078951                0.000000                6.691953   \n",
       "16                   3.408712                0.000000                6.677931   \n",
       "17                   3.828835                0.000000                6.436295   \n",
       "18                   3.842979                0.000000                7.075319   \n",
       "19                   5.956057                0.000000                6.783064   \n",
       "21                   5.791814                0.000000                6.374170   \n",
       "22                   5.733083                0.014355                6.925999   \n",
       "23                   5.450551                0.000000                6.140370   \n",
       "24                   5.039577                0.000000                5.544733   \n",
       "25                   3.303050                0.000000                5.725196   \n",
       "26                   5.660495                0.014355                6.713833   \n",
       "27                   4.856488                0.000000                6.518850   \n",
       "29                   4.900625                0.014355                5.840715   \n",
       "30                   4.716991                0.000000                6.276124   \n",
       "31                   5.975676                0.000000                5.923862   \n",
       "32                   4.646163                0.097611                6.660353   \n",
       "33                   4.660495                0.042644                6.873444   \n",
       "34                   5.358607                0.000000                9.094078   \n",
       "35                   4.684258                0.000000                6.079805   \n",
       "36                   5.881420                0.056584                5.801935   \n",
       "37                   4.905447                0.000000                5.751678   \n",
       "39                   5.503031                0.000000                6.088735   \n",
       "41                   5.767655                0.000000                6.167318   \n",
       "..                        ...                     ...                     ...   \n",
       "780                  0.097611                0.000000                6.028790   \n",
       "781                  0.275007                0.000000                5.451211   \n",
       "782                  0.042644                0.000000                5.048323   \n",
       "783                  1.238787                0.000000                6.520108   \n",
       "785                  0.124328                0.000000                5.638364   \n",
       "787                  0.097611                0.000000                5.425258   \n",
       "791                  0.124328                0.000000                5.057017   \n",
       "792                  0.536053                0.000000                6.628044   \n",
       "793                  0.214125                0.000000                5.990501   \n",
       "795                  0.028569                0.000000                6.013462   \n",
       "799                  0.799087                0.000000                5.416502   \n",
       "800                  5.209453                0.028569                7.189330   \n",
       "803                  6.532629                0.000000                6.397461   \n",
       "805                  4.933573                0.000000                6.876394   \n",
       "806                  3.280956                0.000000                6.034304   \n",
       "807                  4.519164                0.014355                7.469886   \n",
       "808                  2.803227                0.070389                6.342875   \n",
       "811                  4.006298                0.176323                5.995485   \n",
       "814                  0.731183                0.028569                7.058316   \n",
       "816                  3.823749                0.097611                7.425510   \n",
       "818                  5.340918                0.000000                7.235248   \n",
       "819                  5.364572                0.042644                7.337444   \n",
       "824                  4.682573                0.000000                5.667892   \n",
       "833                  0.137504                0.000000                6.451211   \n",
       "834                  0.176323                0.000000                6.665904   \n",
       "836                  2.422233                0.137504                5.987548   \n",
       "837                  5.391974                0.286881                5.888987   \n",
       "838                  4.661636                0.000000                6.648034   \n",
       "839                  4.186659                0.000000                6.263410   \n",
       "840                  4.378512                0.000000                6.340206   \n",
       "\n",
       "     SCYL3 (ENSG00000000457)            ...             \\\n",
       "5                   2.853996            ...              \n",
       "6                   1.918386            ...              \n",
       "7                   2.039138            ...              \n",
       "8                   2.364572            ...              \n",
       "9                   2.895303            ...              \n",
       "13                  1.899176            ...              \n",
       "14                  2.207893            ...              \n",
       "15                  2.121015            ...              \n",
       "16                  2.269033            ...              \n",
       "17                  2.073820            ...              \n",
       "18                  1.963474            ...              \n",
       "19                  2.788686            ...              \n",
       "21                  2.695994            ...              \n",
       "22                  1.871844            ...              \n",
       "23                  2.469886            ...              \n",
       "24                  2.704872            ...              \n",
       "25                  2.735522            ...              \n",
       "26                  2.257011            ...              \n",
       "27                  2.375735            ...              \n",
       "29                  1.871844            ...              \n",
       "30                  2.582556            ...              \n",
       "31                  2.443607            ...              \n",
       "32                  2.286881            ...              \n",
       "33                  1.879706            ...              \n",
       "34                  2.545968            ...              \n",
       "35                  1.735522            ...              \n",
       "36                  3.381283            ...              \n",
       "37                  2.965323            ...              \n",
       "39                  2.731183            ...              \n",
       "41                  3.095924            ...              \n",
       "..                       ...            ...              \n",
       "780                 2.757023            ...              \n",
       "781                 2.889474            ...              \n",
       "782                 1.847997            ...              \n",
       "783                 2.411426            ...              \n",
       "785                 2.339137            ...              \n",
       "787                 2.235727            ...              \n",
       "791                 2.025029            ...              \n",
       "792                 2.664483            ...              \n",
       "793                 2.815575            ...              \n",
       "795                 3.744161            ...              \n",
       "799                 2.722466            ...              \n",
       "800                 2.726831            ...              \n",
       "803                 2.666757            ...              \n",
       "805                 2.467279            ...              \n",
       "806                 1.589763            ...              \n",
       "807                 2.014355            ...              \n",
       "808                 2.021480            ...              \n",
       "811                 2.589763            ...              \n",
       "814                 2.680324            ...              \n",
       "816                 1.790772            ...              \n",
       "818                 2.659925            ...              \n",
       "819                 2.833902            ...              \n",
       "824                 3.285402            ...              \n",
       "833                 3.261531            ...              \n",
       "834                 3.129283            ...              \n",
       "836                 2.229588            ...              \n",
       "837                 4.028569            ...              \n",
       "838                 2.910733            ...              \n",
       "839                 3.599318            ...              \n",
       "840                 2.589763            ...              \n",
       "\n",
       "     NUDT3 (ENSG00000272325)  C6ORF165 (ENSG00000272514)  \\\n",
       "5                   4.694880                    0.137504   \n",
       "6                   3.730096                    0.028569   \n",
       "7                   2.664483                    0.084064   \n",
       "8                   3.658783                    0.739848   \n",
       "9                   3.324811                    2.042644   \n",
       "13                  3.187451                    0.111031   \n",
       "14                  3.861955                    0.137504   \n",
       "15                  3.056584                    0.084064   \n",
       "16                  3.247928                    0.124328   \n",
       "17                  3.782409                    0.526069   \n",
       "18                  2.378512                    0.400538   \n",
       "19                  3.589763                    0.443607   \n",
       "21                  3.560715                    0.056584   \n",
       "22                  3.137504                    0.150560   \n",
       "23                  3.723559                    0.000000   \n",
       "24                  3.003602                    0.000000   \n",
       "25                  3.058316                    0.895303   \n",
       "26                  2.446256                    0.070389   \n",
       "27                  3.494416                    0.495695   \n",
       "29                  3.099295                    0.226509   \n",
       "30                  3.735522                    1.042644   \n",
       "31                  3.496974                    0.070389   \n",
       "32                  3.690417                    1.570463   \n",
       "33                  3.620586                    1.339137   \n",
       "34                  5.468583                    2.771886   \n",
       "35                  3.953265                    0.344828   \n",
       "36                  4.072963                    0.622930   \n",
       "37                  4.350497                    0.622930   \n",
       "39                  4.934988                    0.163499   \n",
       "41                  5.075533                    0.505891   \n",
       "..                       ...                         ...   \n",
       "780                 3.416840                    0.250962   \n",
       "781                 4.112700                    0.014355   \n",
       "782                 4.162693                    0.000000   \n",
       "783                 3.758090                    0.042644   \n",
       "785                 4.899659                    0.000000   \n",
       "787                 4.223423                    0.000000   \n",
       "791                 4.266787                    0.124328   \n",
       "792                 4.304511                    0.400538   \n",
       "793                 5.516330                    0.014355   \n",
       "795                 3.282440                    0.443607   \n",
       "799                 4.095080                    0.000000   \n",
       "800                 3.507160                    0.475085   \n",
       "803                 2.737687                    1.669027   \n",
       "805                 3.650765                    2.014355   \n",
       "806                 3.476382                    0.097611   \n",
       "807                 2.250962                    0.189034   \n",
       "808                 2.920293                    0.250962   \n",
       "811                 4.030336                    0.226509   \n",
       "814                 4.191405                    1.077243   \n",
       "816                 3.295723                    0.286881   \n",
       "818                 2.367371                    0.454176   \n",
       "819                 3.508429                    0.226509   \n",
       "824                 3.397803                    0.485427   \n",
       "833                 3.760221                    0.389567   \n",
       "834                 3.863938                    0.014355   \n",
       "836                 4.268285                    0.000000   \n",
       "837                 3.674687                    0.422233   \n",
       "838                 2.553361                    0.042644   \n",
       "839                 4.546586                    0.000000   \n",
       "840                 3.850999                    0.000000   \n",
       "\n",
       "     MUSTN1 (ENSG00000272573)  DOC2B (ENSG00000272636)  \\\n",
       "5                    0.545968                 3.203201   \n",
       "6                    0.070389                 0.000000   \n",
       "7                    0.226509                 0.000000   \n",
       "8                    0.201634                 0.000000   \n",
       "9                    1.531069                 0.000000   \n",
       "13                   0.526069                 0.000000   \n",
       "14                   0.879706                 0.000000   \n",
       "15                   0.855990                 0.000000   \n",
       "16                   0.000000                 0.000000   \n",
       "17                   0.516015                 0.000000   \n",
       "18                   0.214125                 0.000000   \n",
       "19                   1.084064                 0.070389   \n",
       "21                   0.422233                 0.000000   \n",
       "22                   0.321928                 0.000000   \n",
       "23                   0.201634                 0.042644   \n",
       "24                   1.169925                 0.000000   \n",
       "25                   2.526069                 0.042644   \n",
       "26                   0.298658                 0.389567   \n",
       "27                   0.321928                 0.056584   \n",
       "29                   0.176323                 0.014355   \n",
       "30                   0.163499                 0.000000   \n",
       "31                   0.137504                 0.028569   \n",
       "32                   0.214125                 2.070389   \n",
       "33                   1.250962                 0.918386   \n",
       "34                   0.536053                 2.767655   \n",
       "35                   0.839960                 0.475085   \n",
       "36                   1.097611                 0.111031   \n",
       "37                   0.650765                 1.298658   \n",
       "39                   2.558268                 3.017922   \n",
       "41                   0.454176                 0.137504   \n",
       "..                        ...                      ...   \n",
       "780                  0.879706                 0.028569   \n",
       "781                  0.344828                 0.286881   \n",
       "782                  0.000000                 0.000000   \n",
       "783                  1.182692                 0.000000   \n",
       "785                  0.163499                 0.000000   \n",
       "787                  0.400538                 0.000000   \n",
       "791                  1.570463                 0.000000   \n",
       "792                  0.000000                 0.000000   \n",
       "793                  0.000000                 0.000000   \n",
       "795                  0.695994                 0.000000   \n",
       "799                  2.384050                 0.042644   \n",
       "800                  0.454176                 0.084064   \n",
       "803                  0.516015                 0.000000   \n",
       "805                  0.000000                 0.238787   \n",
       "806                  0.000000                 0.000000   \n",
       "807                  0.137504                 0.000000   \n",
       "808                  0.879706                 0.632268   \n",
       "811                  0.097611                 0.000000   \n",
       "814                  0.526069                 2.253989   \n",
       "816                  0.028569                 0.000000   \n",
       "818                  0.000000                 0.298658   \n",
       "819                  0.000000                 0.443607   \n",
       "824                  0.000000                 0.000000   \n",
       "833                  0.000000                 0.000000   \n",
       "834                  0.111031                 0.000000   \n",
       "836                  0.226509                 0.028569   \n",
       "837                  0.000000                 0.790772   \n",
       "838                  0.201634                 0.111031   \n",
       "839                  0.000000                 0.000000   \n",
       "840                  0.000000                 0.422233   \n",
       "\n",
       "     RP11-309L24.9 (ENSG00000272899)  C2ORF15 (ENSG00000273045)  \\\n",
       "5                           0.978196                   0.669027   \n",
       "6                           1.035624                   2.310340   \n",
       "7                           0.422233                   2.003602   \n",
       "8                           0.378512                   3.557042   \n",
       "9                           0.622930                   3.244887   \n",
       "13                          0.298658                   0.176323   \n",
       "14                          0.333424                   1.490570   \n",
       "15                          0.536053                   0.505891   \n",
       "16                          0.731183                   0.495695   \n",
       "17                          1.021480                   0.687061   \n",
       "18                          1.839960                   0.286881   \n",
       "19                          1.664483                   0.823749   \n",
       "21                          0.250962                   2.211012   \n",
       "22                          0.111031                   2.408712   \n",
       "23                          0.695994                   3.264536   \n",
       "24                          0.238787                   1.823749   \n",
       "25                          1.500802                   1.356144   \n",
       "26                          1.169925                   2.992768   \n",
       "27                          0.214125                   1.867896   \n",
       "29                          0.389567                   3.280956   \n",
       "30                          0.097611                   2.378512   \n",
       "31                          0.555816                   1.327687   \n",
       "32                          0.389567                   0.555816   \n",
       "33                          0.485427                   0.695994   \n",
       "34                          0.925999                   0.807355   \n",
       "35                          0.613532                   0.933573   \n",
       "36                          0.565597                   2.472488   \n",
       "37                          1.827819                   3.505891   \n",
       "39                          1.028569                   0.948601   \n",
       "41                          1.137504                   4.237258   \n",
       "..                               ...                        ...   \n",
       "780                         1.070389                   0.941106   \n",
       "781                         0.604071                   0.226509   \n",
       "782                         0.189034                   0.695994   \n",
       "783                         0.505891                   0.176323   \n",
       "785                         0.226509                   0.516015   \n",
       "787                         0.124328                   0.214125   \n",
       "791                         1.505891                   1.622930   \n",
       "792                         1.400538                   1.137504   \n",
       "793                         0.765535                   2.266037   \n",
       "795                         1.028569                   1.316146   \n",
       "799                         0.000000                   2.942984   \n",
       "800                         0.250962                   1.056584   \n",
       "803                         0.189034                   3.070389   \n",
       "805                         0.084064                   3.808385   \n",
       "806                         0.163499                   0.056584   \n",
       "807                         0.604071                   2.217231   \n",
       "808                         0.214125                   0.378512   \n",
       "811                         1.124328                   1.298658   \n",
       "814                         0.432959                   0.389567   \n",
       "816                         0.111031                   0.516015   \n",
       "818                         0.536053                   2.070389   \n",
       "819                         0.632268                   3.440952   \n",
       "824                         0.333424                   4.519793   \n",
       "833                         1.316146                   0.622930   \n",
       "834                         1.316146                   1.967169   \n",
       "836                         0.933573                   1.014355   \n",
       "837                         0.495695                   3.063503   \n",
       "838                         0.536053                   2.130931   \n",
       "839                         1.811471                   3.231125   \n",
       "840                         1.169925                   3.220330   \n",
       "\n",
       "     GRIN2B (ENSG00000273079)  SNURF (ENSG00000273173)  \\\n",
       "5                    0.000000                 7.092229   \n",
       "6                    0.000000                 0.641546   \n",
       "7                    0.000000                 5.660210   \n",
       "8                    0.000000                 6.843607   \n",
       "9                    0.000000                 5.405312   \n",
       "13                   0.000000                 6.463524   \n",
       "14                   0.056584                 7.145372   \n",
       "15                   0.014355                 6.101818   \n",
       "16                   0.000000                 0.669027   \n",
       "17                   0.014355                 6.302685   \n",
       "18                   0.000000                 6.239551   \n",
       "19                   0.000000                 7.531459   \n",
       "21                   0.000000                 0.150560   \n",
       "22                   0.000000                 5.715893   \n",
       "23                   0.000000                 7.594698   \n",
       "24                   0.000000                 5.014355   \n",
       "25                   0.014355                 5.731455   \n",
       "26                   0.000000                 0.163499   \n",
       "27                   0.014355                 7.179909   \n",
       "29                   0.000000                 0.389567   \n",
       "30                   0.000000                 0.594549   \n",
       "31                   0.000000                 6.479619   \n",
       "32                   0.014355                 6.827311   \n",
       "33                   0.111031                 6.529821   \n",
       "34                   1.807355                 7.774524   \n",
       "35                   0.000000                 7.227857   \n",
       "36                   0.124328                 7.428863   \n",
       "37                   0.286881                 0.097611   \n",
       "39                   0.454176                 7.614195   \n",
       "41                   0.028569                 7.693905   \n",
       "..                        ...                      ...   \n",
       "780                  0.000000                 6.710531   \n",
       "781                  0.000000                 6.780310   \n",
       "782                  0.000000                 6.224773   \n",
       "783                  0.000000                 5.548128   \n",
       "785                  0.000000                 5.473787   \n",
       "787                  0.000000                 7.093919   \n",
       "791                  0.097611                 0.344828   \n",
       "792                  0.028569                 4.929318   \n",
       "793                  0.042644                 6.338068   \n",
       "795                  0.000000                 0.150560   \n",
       "799                  0.000000                 7.064797   \n",
       "800                  0.000000                 6.718636   \n",
       "803                  0.250962                 4.205549   \n",
       "805                  0.000000                 6.652773   \n",
       "806                  0.000000                 6.233044   \n",
       "807                  0.344828                 0.042644   \n",
       "808                  0.389567                 7.059615   \n",
       "811                  0.028569                 7.577580   \n",
       "814                  0.250962                 0.321928   \n",
       "816                  0.014355                 0.028569   \n",
       "818                  0.028569                 0.150560   \n",
       "819                  0.000000                 0.097611   \n",
       "824                  0.000000                 0.650765   \n",
       "833                  0.000000                 5.961623   \n",
       "834                  0.000000                 6.111657   \n",
       "836                  0.000000                 4.789729   \n",
       "837                  0.238787                 6.004501   \n",
       "838                  0.056584                 0.238787   \n",
       "839                  0.948601                 1.063503   \n",
       "840                  0.124328                 0.963474   \n",
       "\n",
       "     RP11-1263C18.1 (ENSG00000273238)  ZBTB8B (ENSG00000273274)  \n",
       "5                            0.669027                  0.042644  \n",
       "6                            0.000000                  0.000000  \n",
       "7                            0.000000                  0.432959  \n",
       "8                            0.000000                  0.948601  \n",
       "9                            0.000000                  1.077243  \n",
       "13                           0.650765                  0.014355  \n",
       "14                           0.000000                  0.757023  \n",
       "15                           0.000000                  0.704872  \n",
       "16                           0.000000                  0.028569  \n",
       "17                           0.000000                  0.000000  \n",
       "18                           0.000000                  0.000000  \n",
       "19                           0.111031                  0.056584  \n",
       "21                           0.000000                  0.084064  \n",
       "22                           0.000000                  0.070389  \n",
       "23                           0.000000                  0.070389  \n",
       "24                           0.097611                  0.000000  \n",
       "25                           0.000000                  0.014355  \n",
       "26                           0.000000                  0.028569  \n",
       "27                           0.000000                  0.344828  \n",
       "29                           0.000000                  0.250962  \n",
       "30                           0.000000                  0.000000  \n",
       "31                           0.000000                  0.014355  \n",
       "32                           0.000000                  0.084064  \n",
       "33                           0.000000                  0.815575  \n",
       "34                           1.570463                  1.422233  \n",
       "35                           0.443607                  0.150560  \n",
       "36                           0.000000                  1.117695  \n",
       "37                           1.510962                  2.375735  \n",
       "39                           0.238787                  1.090853  \n",
       "41                           2.788686                  1.761285  \n",
       "..                                ...                       ...  \n",
       "780                          0.084064                  0.000000  \n",
       "781                          0.298658                  0.000000  \n",
       "782                          0.000000                  0.000000  \n",
       "783                          0.000000                  0.014355  \n",
       "785                          0.000000                  0.000000  \n",
       "787                          0.000000                  0.014355  \n",
       "791                          0.000000                  0.000000  \n",
       "792                          0.000000                  0.000000  \n",
       "793                          0.000000                  0.000000  \n",
       "795                          0.000000                  0.000000  \n",
       "799                          0.000000                  0.000000  \n",
       "800                          0.000000                  0.137504  \n",
       "803                          0.000000                  0.250962  \n",
       "805                          0.000000                  0.378512  \n",
       "806                          0.000000                  0.000000  \n",
       "807                          0.056584                  0.622930  \n",
       "808                          0.000000                  0.536053  \n",
       "811                          0.000000                  0.000000  \n",
       "814                          0.000000                  0.014355  \n",
       "816                          0.000000                  0.000000  \n",
       "818                          0.000000                  0.000000  \n",
       "819                          0.000000                  0.000000  \n",
       "824                          0.000000                  0.014355  \n",
       "833                          0.000000                  0.000000  \n",
       "834                          0.000000                  0.000000  \n",
       "836                          0.000000                  0.070389  \n",
       "837                          0.000000                  0.084064  \n",
       "838                          0.000000                  0.000000  \n",
       "839                          0.000000                  0.042644  \n",
       "840                          0.000000                  0.000000  \n",
       "\n",
       "[515 rows x 18826 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Olararib_1017 = pd.read_csv(os.path.join(Galaxy_ML, 'galaxy_ml/test-data/Olaparib_1017.tsv.gz'), sep='\\t', index_col=0)\n",
    "Olararib_1017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "markers",
         "name": "y_ture",
         "type": "scatter",
         "uid": "a9034810-7ab8-11e9-985f-4a0002d544a0",
         "y": [
          0.846324,
          0.970014,
          0.915457,
          0.987345,
          0.95223,
          0.922807,
          0.90152,
          0.901069,
          0.960333,
          0.983662,
          0.966786,
          0.927201,
          0.979913,
          0.96347,
          0.988805,
          0.981728,
          0.984961,
          0.98486,
          0.898666,
          0.986679,
          0.986086,
          0.965271,
          0.982635,
          0.97983,
          0.978489,
          0.947174,
          0.909941,
          0.977466,
          0.98778,
          0.991654,
          0.992041,
          0.7012390000000001,
          0.967739,
          0.983675,
          0.965821,
          0.986085,
          0.982222,
          0.97829,
          0.982443,
          0.988192,
          0.97476,
          0.955852,
          0.984228,
          0.934694,
          0.969182,
          0.965982,
          0.968862,
          0.981638,
          0.987415,
          0.959881,
          0.984504,
          0.986945,
          0.987008,
          0.940811,
          0.990678,
          0.971132,
          0.974241,
          0.957105,
          0.98449,
          0.970932,
          0.971123,
          0.925926,
          0.934544,
          0.963561,
          0.983071,
          0.974828,
          0.986139,
          0.977432,
          0.968981,
          0.958603,
          0.96903,
          0.95785,
          0.988531,
          0.982861,
          0.98177,
          0.953012,
          0.983922,
          0.968515,
          0.979395,
          0.959971,
          0.980965,
          0.962305,
          0.984881,
          0.912514,
          0.980526,
          0.981018,
          0.98126,
          0.987488,
          0.984837,
          0.970342,
          0.95128,
          0.985455,
          0.979123,
          0.974976,
          0.965584,
          0.940719,
          0.985255,
          0.98546,
          0.987728,
          0.982815,
          0.97907,
          0.947534,
          0.928412,
          0.969662,
          0.962959,
          0.926848,
          0.977071,
          0.945723,
          0.977249,
          0.981789,
          0.965384,
          0.980644,
          0.941606,
          0.951644,
          0.973152,
          0.94495,
          0.934516,
          0.982751,
          0.979792,
          0.978406,
          0.977376,
          0.884085,
          0.931396,
          0.954727,
          0.984236,
          0.985432,
          0.959679,
          0.950057,
          0.983622,
          0.978385,
          0.953181,
          0.920156,
          0.916175,
          0.988731,
          0.978208,
          0.937738,
          0.824882,
          0.983937,
          0.937517,
          0.983051,
          0.550395,
          0.982899,
          0.977076,
          0.916806,
          0.959756,
          0.988297,
          0.976909,
          0.986964,
          0.98655,
          0.896548,
          0.98557,
          0.936006,
          0.979856,
          0.991741,
          0.96517,
          0.978676,
          0.8733350000000001,
          0.984021,
          0.966646,
          0.952114,
          0.954449,
          0.961351,
          0.978119,
          0.921627,
          0.988319,
          0.988244,
          0.984369,
          0.987301,
          0.942963,
          0.933651,
          0.988197,
          0.8629979999999999,
          0.981669,
          0.980967,
          0.987024,
          0.907095,
          0.8948659999999999,
          0.976694,
          0.934446,
          0.957294,
          0.988786,
          0.984688,
          0.976117,
          0.981095,
          0.930067,
          0.973827,
          0.987701,
          0.882785,
          0.869765,
          0.989356,
          0.986573,
          0.968758,
          0.990294,
          0.990259,
          0.989679,
          0.984419,
          0.96852,
          0.983755,
          0.990265,
          0.991392,
          0.987992,
          0.961418,
          0.97714,
          0.969542,
          0.984955,
          0.978853,
          0.988123,
          0.988384,
          0.988459,
          0.983853,
          0.937813,
          0.9866,
          0.958591,
          0.989062,
          0.965672,
          0.959246,
          0.984136,
          0.998264,
          0.987666,
          0.986035,
          0.98516,
          0.979577,
          0.975771,
          0.964073,
          0.974678,
          0.978199,
          0.949746,
          0.993783,
          0.660406,
          0.980894,
          0.942149,
          0.908404,
          0.973546,
          0.979699,
          0.990857,
          0.8606299999999999,
          0.943223,
          0.985108,
          0.933697,
          0.987667,
          0.972072,
          0.984489,
          0.973029,
          0.948328,
          0.885316,
          0.979969,
          0.800239,
          0.980995,
          0.980417,
          0.979592,
          0.984398,
          0.984432,
          0.970339,
          0.948598,
          0.983384,
          0.966779,
          0.989827,
          0.940577,
          0.982002,
          0.983802,
          0.959221,
          0.963233,
          0.8893909999999999,
          0.993632,
          0.978272,
          0.980687,
          0.923699,
          0.99087,
          0.975953,
          0.985267,
          0.984864,
          0.978823,
          0.978545,
          0.983181,
          0.989018,
          0.978512,
          0.981275,
          0.981525,
          0.984407,
          0.974511,
          0.984317,
          0.978094,
          0.993184,
          0.981626,
          0.980138,
          0.985715,
          0.985306,
          0.984921,
          0.924393,
          0.871182,
          0.982927,
          0.981194,
          0.986324,
          0.963642,
          0.986585,
          0.985787,
          0.988077,
          0.984152,
          0.981995,
          0.981297,
          0.989058,
          0.991228,
          0.991186,
          0.937246,
          0.979851,
          0.980619,
          0.954498,
          0.982689,
          0.963631,
          0.982656,
          0.984469,
          0.989698,
          0.984676,
          0.986899,
          0.972743,
          0.965318,
          0.98319,
          0.988046,
          0.977013,
          0.987663,
          0.977115,
          0.987859,
          0.966231,
          0.984595,
          0.954614,
          0.982753,
          0.974195,
          0.994206,
          0.7468739999999999,
          0.983725,
          0.933224,
          0.97836,
          0.9903,
          0.975052,
          0.913177,
          0.98465,
          0.94473,
          0.979799,
          0.986803,
          0.976507,
          0.944908,
          0.984663,
          0.903251,
          0.861701,
          0.985245,
          0.989288,
          0.954558,
          0.967176,
          0.968799,
          0.985086,
          0.985187,
          0.964252,
          0.974389,
          0.955655,
          0.914612,
          0.980239,
          0.978267,
          0.9761,
          0.961565,
          0.98321,
          0.983723,
          0.981746,
          0.980922,
          0.983554,
          0.987857,
          0.965405,
          0.987073,
          0.989779,
          0.964427,
          0.984452,
          0.949623,
          0.980568,
          0.977722,
          0.973045,
          0.973861,
          0.972256,
          0.922201,
          0.938742,
          0.989958,
          0.946365,
          0.97275,
          0.988598,
          0.973107,
          0.93715,
          0.928915,
          0.92713,
          0.970481,
          0.987022,
          0.988008,
          0.961638,
          0.989049,
          0.984973,
          0.987163,
          0.982181,
          0.926533,
          0.993797,
          0.985666,
          0.959347,
          0.94308,
          0.987789,
          0.962442,
          0.985515,
          0.876835,
          0.926599,
          0.986252,
          0.973904,
          0.981335,
          0.975544,
          0.924952,
          0.979027,
          0.985705,
          0.958277,
          0.986422,
          0.954033,
          0.965809,
          0.7833060000000001,
          0.757314,
          0.966351,
          0.958867,
          0.986347,
          0.975447,
          0.984408,
          0.960626,
          0.984541,
          0.946383,
          0.949952,
          0.976835,
          0.947554,
          0.98726,
          0.96577,
          0.984951,
          0.981381,
          0.990947,
          0.986702,
          0.989673,
          0.992589,
          0.938656,
          0.96867,
          0.966923,
          0.983321,
          0.949541,
          0.985767,
          0.984232,
          0.986238,
          0.912207,
          0.970838,
          0.971764,
          0.988987,
          0.963018,
          0.979272,
          0.985357,
          0.988148,
          0.956862,
          0.957124,
          0.944323,
          0.977904,
          0.967043,
          0.980338,
          0.882099,
          0.987223,
          0.973345,
          0.980864,
          0.984656,
          0.960606,
          0.961614,
          0.960892,
          0.989591,
          0.990859,
          0.963755,
          0.964081,
          0.964748,
          0.992622,
          0.959949,
          0.900971,
          0.990914,
          0.988136,
          0.891691,
          0.992351,
          0.982682,
          0.98297,
          0.942187,
          0.933239,
          0.972036,
          0.990768,
          0.853317,
          0.961092,
          0.961127,
          0.881394,
          0.992637,
          0.982835,
          0.867959,
          0.997365,
          0.883126,
          0.995314,
          0.8929459999999999,
          0.985744,
          0.992005,
          0.975499,
          0.979747,
          0.870613,
          0.977301,
          0.968143,
          0.857144,
          0.974048,
          0.985873,
          0.959242,
          0.989116,
          0.987574,
          0.966985,
          0.984661,
          0.983232,
          0.949313,
          0.947596,
          0.964075,
          0.981441
         ]
        }
       ],
       "layout": {
        "title": "Distribution of target y",
        "xaxis": {
         "title": "Sample No."
        },
        "yaxis": {
         "title": "Value"
        }
       }
      },
      "text/html": [
       "<div id=\"2d1589f3-7024-4fab-af35-322043cf163c\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"2d1589f3-7024-4fab-af35-322043cf163c\", [{\"mode\": \"markers\", \"name\": \"y_ture\", \"y\": [0.846324, 0.970014, 0.915457, 0.987345, 0.95223, 0.922807, 0.90152, 0.901069, 0.960333, 0.983662, 0.966786, 0.927201, 0.979913, 0.96347, 0.988805, 0.981728, 0.984961, 0.98486, 0.898666, 0.986679, 0.986086, 0.965271, 0.982635, 0.97983, 0.978489, 0.947174, 0.909941, 0.977466, 0.98778, 0.991654, 0.992041, 0.7012390000000001, 0.967739, 0.983675, 0.965821, 0.986085, 0.982222, 0.97829, 0.982443, 0.988192, 0.97476, 0.955852, 0.984228, 0.934694, 0.969182, 0.965982, 0.968862, 0.981638, 0.987415, 0.959881, 0.984504, 0.986945, 0.987008, 0.940811, 0.990678, 0.971132, 0.974241, 0.957105, 0.98449, 0.970932, 0.971123, 0.925926, 0.934544, 0.963561, 0.983071, 0.974828, 0.986139, 0.977432, 0.968981, 0.958603, 0.96903, 0.95785, 0.988531, 0.982861, 0.98177, 0.953012, 0.983922, 0.968515, 0.979395, 0.959971, 0.980965, 0.962305, 0.984881, 0.912514, 0.980526, 0.981018, 0.98126, 0.987488, 0.984837, 0.970342, 0.95128, 0.985455, 0.979123, 0.974976, 0.965584, 0.940719, 0.985255, 0.98546, 0.987728, 0.982815, 0.97907, 0.947534, 0.928412, 0.969662, 0.962959, 0.926848, 0.977071, 0.945723, 0.977249, 0.981789, 0.965384, 0.980644, 0.941606, 0.951644, 0.973152, 0.94495, 0.934516, 0.982751, 0.979792, 0.978406, 0.977376, 0.884085, 0.931396, 0.954727, 0.984236, 0.985432, 0.959679, 0.950057, 0.983622, 0.978385, 0.953181, 0.920156, 0.916175, 0.988731, 0.978208, 0.937738, 0.824882, 0.983937, 0.937517, 0.983051, 0.550395, 0.982899, 0.977076, 0.916806, 0.959756, 0.988297, 0.976909, 0.986964, 0.98655, 0.896548, 0.98557, 0.936006, 0.979856, 0.991741, 0.96517, 0.978676, 0.8733350000000001, 0.984021, 0.966646, 0.952114, 0.954449, 0.961351, 0.978119, 0.921627, 0.988319, 0.988244, 0.984369, 0.987301, 0.942963, 0.933651, 0.988197, 0.8629979999999999, 0.981669, 0.980967, 0.987024, 0.907095, 0.8948659999999999, 0.976694, 0.934446, 0.957294, 0.988786, 0.984688, 0.976117, 0.981095, 0.930067, 0.973827, 0.987701, 0.882785, 0.869765, 0.989356, 0.986573, 0.968758, 0.990294, 0.990259, 0.989679, 0.984419, 0.96852, 0.983755, 0.990265, 0.991392, 0.987992, 0.961418, 0.97714, 0.969542, 0.984955, 0.978853, 0.988123, 0.988384, 0.988459, 0.983853, 0.937813, 0.9866, 0.958591, 0.989062, 0.965672, 0.959246, 0.984136, 0.998264, 0.987666, 0.986035, 0.98516, 0.979577, 0.975771, 0.964073, 0.974678, 0.978199, 0.949746, 0.993783, 0.660406, 0.980894, 0.942149, 0.908404, 0.973546, 0.979699, 0.990857, 0.8606299999999999, 0.943223, 0.985108, 0.933697, 0.987667, 0.972072, 0.984489, 0.973029, 0.948328, 0.885316, 0.979969, 0.800239, 0.980995, 0.980417, 0.979592, 0.984398, 0.984432, 0.970339, 0.948598, 0.983384, 0.966779, 0.989827, 0.940577, 0.982002, 0.983802, 0.959221, 0.963233, 0.8893909999999999, 0.993632, 0.978272, 0.980687, 0.923699, 0.99087, 0.975953, 0.985267, 0.984864, 0.978823, 0.978545, 0.983181, 0.989018, 0.978512, 0.981275, 0.981525, 0.984407, 0.974511, 0.984317, 0.978094, 0.993184, 0.981626, 0.980138, 0.985715, 0.985306, 0.984921, 0.924393, 0.871182, 0.982927, 0.981194, 0.986324, 0.963642, 0.986585, 0.985787, 0.988077, 0.984152, 0.981995, 0.981297, 0.989058, 0.991228, 0.991186, 0.937246, 0.979851, 0.980619, 0.954498, 0.982689, 0.963631, 0.982656, 0.984469, 0.989698, 0.984676, 0.986899, 0.972743, 0.965318, 0.98319, 0.988046, 0.977013, 0.987663, 0.977115, 0.987859, 0.966231, 0.984595, 0.954614, 0.982753, 0.974195, 0.994206, 0.7468739999999999, 0.983725, 0.933224, 0.97836, 0.9903, 0.975052, 0.913177, 0.98465, 0.94473, 0.979799, 0.986803, 0.976507, 0.944908, 0.984663, 0.903251, 0.861701, 0.985245, 0.989288, 0.954558, 0.967176, 0.968799, 0.985086, 0.985187, 0.964252, 0.974389, 0.955655, 0.914612, 0.980239, 0.978267, 0.9761, 0.961565, 0.98321, 0.983723, 0.981746, 0.980922, 0.983554, 0.987857, 0.965405, 0.987073, 0.989779, 0.964427, 0.984452, 0.949623, 0.980568, 0.977722, 0.973045, 0.973861, 0.972256, 0.922201, 0.938742, 0.989958, 0.946365, 0.97275, 0.988598, 0.973107, 0.93715, 0.928915, 0.92713, 0.970481, 0.987022, 0.988008, 0.961638, 0.989049, 0.984973, 0.987163, 0.982181, 0.926533, 0.993797, 0.985666, 0.959347, 0.94308, 0.987789, 0.962442, 0.985515, 0.876835, 0.926599, 0.986252, 0.973904, 0.981335, 0.975544, 0.924952, 0.979027, 0.985705, 0.958277, 0.986422, 0.954033, 0.965809, 0.7833060000000001, 0.757314, 0.966351, 0.958867, 0.986347, 0.975447, 0.984408, 0.960626, 0.984541, 0.946383, 0.949952, 0.976835, 0.947554, 0.98726, 0.96577, 0.984951, 0.981381, 0.990947, 0.986702, 0.989673, 0.992589, 0.938656, 0.96867, 0.966923, 0.983321, 0.949541, 0.985767, 0.984232, 0.986238, 0.912207, 0.970838, 0.971764, 0.988987, 0.963018, 0.979272, 0.985357, 0.988148, 0.956862, 0.957124, 0.944323, 0.977904, 0.967043, 0.980338, 0.882099, 0.987223, 0.973345, 0.980864, 0.984656, 0.960606, 0.961614, 0.960892, 0.989591, 0.990859, 0.963755, 0.964081, 0.964748, 0.992622, 0.959949, 0.900971, 0.990914, 0.988136, 0.891691, 0.992351, 0.982682, 0.98297, 0.942187, 0.933239, 0.972036, 0.990768, 0.853317, 0.961092, 0.961127, 0.881394, 0.992637, 0.982835, 0.867959, 0.997365, 0.883126, 0.995314, 0.8929459999999999, 0.985744, 0.992005, 0.975499, 0.979747, 0.870613, 0.977301, 0.968143, 0.857144, 0.974048, 0.985873, 0.959242, 0.989116, 0.987574, 0.966985, 0.984661, 0.983232, 0.949313, 0.947596, 0.964075, 0.981441], \"type\": \"scatter\", \"uid\": \"a9034810-7ab8-11e9-985f-4a0002d544a0\"}], {\"title\": \"Distribution of target y\", \"xaxis\": {\"title\": \"Sample No.\"}, \"yaxis\": {\"title\": \"Value\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"2d1589f3-7024-4fab-af35-322043cf163c\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"2d1589f3-7024-4fab-af35-322043cf163c\", [{\"mode\": \"markers\", \"name\": \"y_ture\", \"y\": [0.846324, 0.970014, 0.915457, 0.987345, 0.95223, 0.922807, 0.90152, 0.901069, 0.960333, 0.983662, 0.966786, 0.927201, 0.979913, 0.96347, 0.988805, 0.981728, 0.984961, 0.98486, 0.898666, 0.986679, 0.986086, 0.965271, 0.982635, 0.97983, 0.978489, 0.947174, 0.909941, 0.977466, 0.98778, 0.991654, 0.992041, 0.7012390000000001, 0.967739, 0.983675, 0.965821, 0.986085, 0.982222, 0.97829, 0.982443, 0.988192, 0.97476, 0.955852, 0.984228, 0.934694, 0.969182, 0.965982, 0.968862, 0.981638, 0.987415, 0.959881, 0.984504, 0.986945, 0.987008, 0.940811, 0.990678, 0.971132, 0.974241, 0.957105, 0.98449, 0.970932, 0.971123, 0.925926, 0.934544, 0.963561, 0.983071, 0.974828, 0.986139, 0.977432, 0.968981, 0.958603, 0.96903, 0.95785, 0.988531, 0.982861, 0.98177, 0.953012, 0.983922, 0.968515, 0.979395, 0.959971, 0.980965, 0.962305, 0.984881, 0.912514, 0.980526, 0.981018, 0.98126, 0.987488, 0.984837, 0.970342, 0.95128, 0.985455, 0.979123, 0.974976, 0.965584, 0.940719, 0.985255, 0.98546, 0.987728, 0.982815, 0.97907, 0.947534, 0.928412, 0.969662, 0.962959, 0.926848, 0.977071, 0.945723, 0.977249, 0.981789, 0.965384, 0.980644, 0.941606, 0.951644, 0.973152, 0.94495, 0.934516, 0.982751, 0.979792, 0.978406, 0.977376, 0.884085, 0.931396, 0.954727, 0.984236, 0.985432, 0.959679, 0.950057, 0.983622, 0.978385, 0.953181, 0.920156, 0.916175, 0.988731, 0.978208, 0.937738, 0.824882, 0.983937, 0.937517, 0.983051, 0.550395, 0.982899, 0.977076, 0.916806, 0.959756, 0.988297, 0.976909, 0.986964, 0.98655, 0.896548, 0.98557, 0.936006, 0.979856, 0.991741, 0.96517, 0.978676, 0.8733350000000001, 0.984021, 0.966646, 0.952114, 0.954449, 0.961351, 0.978119, 0.921627, 0.988319, 0.988244, 0.984369, 0.987301, 0.942963, 0.933651, 0.988197, 0.8629979999999999, 0.981669, 0.980967, 0.987024, 0.907095, 0.8948659999999999, 0.976694, 0.934446, 0.957294, 0.988786, 0.984688, 0.976117, 0.981095, 0.930067, 0.973827, 0.987701, 0.882785, 0.869765, 0.989356, 0.986573, 0.968758, 0.990294, 0.990259, 0.989679, 0.984419, 0.96852, 0.983755, 0.990265, 0.991392, 0.987992, 0.961418, 0.97714, 0.969542, 0.984955, 0.978853, 0.988123, 0.988384, 0.988459, 0.983853, 0.937813, 0.9866, 0.958591, 0.989062, 0.965672, 0.959246, 0.984136, 0.998264, 0.987666, 0.986035, 0.98516, 0.979577, 0.975771, 0.964073, 0.974678, 0.978199, 0.949746, 0.993783, 0.660406, 0.980894, 0.942149, 0.908404, 0.973546, 0.979699, 0.990857, 0.8606299999999999, 0.943223, 0.985108, 0.933697, 0.987667, 0.972072, 0.984489, 0.973029, 0.948328, 0.885316, 0.979969, 0.800239, 0.980995, 0.980417, 0.979592, 0.984398, 0.984432, 0.970339, 0.948598, 0.983384, 0.966779, 0.989827, 0.940577, 0.982002, 0.983802, 0.959221, 0.963233, 0.8893909999999999, 0.993632, 0.978272, 0.980687, 0.923699, 0.99087, 0.975953, 0.985267, 0.984864, 0.978823, 0.978545, 0.983181, 0.989018, 0.978512, 0.981275, 0.981525, 0.984407, 0.974511, 0.984317, 0.978094, 0.993184, 0.981626, 0.980138, 0.985715, 0.985306, 0.984921, 0.924393, 0.871182, 0.982927, 0.981194, 0.986324, 0.963642, 0.986585, 0.985787, 0.988077, 0.984152, 0.981995, 0.981297, 0.989058, 0.991228, 0.991186, 0.937246, 0.979851, 0.980619, 0.954498, 0.982689, 0.963631, 0.982656, 0.984469, 0.989698, 0.984676, 0.986899, 0.972743, 0.965318, 0.98319, 0.988046, 0.977013, 0.987663, 0.977115, 0.987859, 0.966231, 0.984595, 0.954614, 0.982753, 0.974195, 0.994206, 0.7468739999999999, 0.983725, 0.933224, 0.97836, 0.9903, 0.975052, 0.913177, 0.98465, 0.94473, 0.979799, 0.986803, 0.976507, 0.944908, 0.984663, 0.903251, 0.861701, 0.985245, 0.989288, 0.954558, 0.967176, 0.968799, 0.985086, 0.985187, 0.964252, 0.974389, 0.955655, 0.914612, 0.980239, 0.978267, 0.9761, 0.961565, 0.98321, 0.983723, 0.981746, 0.980922, 0.983554, 0.987857, 0.965405, 0.987073, 0.989779, 0.964427, 0.984452, 0.949623, 0.980568, 0.977722, 0.973045, 0.973861, 0.972256, 0.922201, 0.938742, 0.989958, 0.946365, 0.97275, 0.988598, 0.973107, 0.93715, 0.928915, 0.92713, 0.970481, 0.987022, 0.988008, 0.961638, 0.989049, 0.984973, 0.987163, 0.982181, 0.926533, 0.993797, 0.985666, 0.959347, 0.94308, 0.987789, 0.962442, 0.985515, 0.876835, 0.926599, 0.986252, 0.973904, 0.981335, 0.975544, 0.924952, 0.979027, 0.985705, 0.958277, 0.986422, 0.954033, 0.965809, 0.7833060000000001, 0.757314, 0.966351, 0.958867, 0.986347, 0.975447, 0.984408, 0.960626, 0.984541, 0.946383, 0.949952, 0.976835, 0.947554, 0.98726, 0.96577, 0.984951, 0.981381, 0.990947, 0.986702, 0.989673, 0.992589, 0.938656, 0.96867, 0.966923, 0.983321, 0.949541, 0.985767, 0.984232, 0.986238, 0.912207, 0.970838, 0.971764, 0.988987, 0.963018, 0.979272, 0.985357, 0.988148, 0.956862, 0.957124, 0.944323, 0.977904, 0.967043, 0.980338, 0.882099, 0.987223, 0.973345, 0.980864, 0.984656, 0.960606, 0.961614, 0.960892, 0.989591, 0.990859, 0.963755, 0.964081, 0.964748, 0.992622, 0.959949, 0.900971, 0.990914, 0.988136, 0.891691, 0.992351, 0.982682, 0.98297, 0.942187, 0.933239, 0.972036, 0.990768, 0.853317, 0.961092, 0.961127, 0.881394, 0.992637, 0.982835, 0.867959, 0.997365, 0.883126, 0.995314, 0.8929459999999999, 0.985744, 0.992005, 0.975499, 0.979747, 0.870613, 0.977301, 0.968143, 0.857144, 0.974048, 0.985873, 0.959242, 0.989116, 0.987574, 0.966985, 0.984661, 0.983232, 0.949313, 0.947596, 0.964075, 0.981441], \"type\": \"scatter\", \"uid\": \"a9034810-7ab8-11e9-985f-4a0002d544a0\"}], {\"title\": \"Distribution of target y\", \"xaxis\": {\"title\": \"Sample No.\"}, \"yaxis\": {\"title\": \"Value\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = Olararib_1017.iloc[:, 6:].values, Olararib_1017.iloc[:, 5].values.ravel()\n",
    "data1 = go.Scatter(\n",
    "        y = y,\n",
    "        mode = \"markers\",\n",
    "        name = \"y_ture\",\n",
    ")\n",
    "\n",
    "layout = dict(\n",
    "    xaxis=dict(\n",
    "        title='Sample No.'\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Value'\n",
    "    ),\n",
    "    title=\"Distribution of target y\"\n",
    "    \n",
    ")\n",
    "fig = go.Figure(data=[data1], layout=layout)\n",
    "iplot(fig)\n",
    "\n",
    "# To show plot, paste the link to this GitHub notebook into http://nbviewer.jupyter.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared testing parameters\n",
    "from iraps_classifier import IRAPSCore, IRAPSClassifier\n",
    "from iraps_classifier import binarize_auc_scorer, binarize_average_precision_scorer\n",
    "from iraps_classifier import BinarizeTargetTransformer\n",
    "from model_validations import OrderedKFold, RepeatedOrderedKFold\n",
    "\n",
    "cv = OrderedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "scoring = {\n",
    "    'ap': binarize_average_precision_scorer,\n",
    "    'auc': binarize_auc_scorer\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([0.86160016, 0.85600901, 0.85827184, 0.85818601, 0.8872931 ]),\n",
       "  'score_time': array([0.01232386, 0.01170301, 0.01711082, 0.01590991, 0.01007795]),\n",
       "  'test_ap': array([0.13490267, 0.14858907, 0.09597874, 0.09858755, 0.12532637]),\n",
       "  'train_ap': array([0.99868421, 0.99857752, 1.        , 1.        , 0.99117351]),\n",
       "  'test_auc': array([0.49784946, 0.72576832, 0.51950355, 0.48387097, 0.64184397]),\n",
       "  'train_auc': array([0.99992964, 0.99992793, 1.        , 1.        , 0.99929637])},\n",
       " 0.12067688101574414,\n",
       " 0.5737672538702052)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "model = ensemble.RandomForestClassifier(random_state=0, class_weight=\"balanced\")\n",
    "estimator = BinarizeTargetClassifier(model)\n",
    "\n",
    "rval = rval_rfc = cross_validate(estimator, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([37.2194407 , 37.08532286, 38.15170002, 44.18254685, 23.02951121]),\n",
       "  'score_time': array([0.01522994, 0.01655984, 0.0124321 , 0.01369405, 0.0097177 ]),\n",
       "  'test_ap': array([0.193065  , 0.27374859, 0.11484267, 0.23472446, 0.08524331]),\n",
       "  'train_ap': array([0.88710804, 0.84430983, 0.87371068, 0.89847941, 0.9155982 ]),\n",
       "  'test_auc': array([0.63333333, 0.64775414, 0.46690307, 0.64623656, 0.46926714]),\n",
       "  'train_auc': array([0.98592739, 0.98032432, 0.98601802, 0.98560252, 0.98853082])},\n",
       " 0.18032480387682087,\n",
       " 0.572698848470983)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForestRegressor\n",
    "model = ensemble.RandomForestRegressor(random_state=0)\n",
    "estimator = BinarizeTargetRegressor(model)\n",
    "\n",
    "rval = rval_rfr = cross_validate(estimator, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([95.18019509, 95.06028199, 82.76291513, 82.86060071, 66.92184901]),\n",
       "  'score_time': array([0.20289898, 0.18975186, 0.17431092, 0.17913127, 0.1443491 ]),\n",
       "  'test_ap': array([0.1825592 , 0.20934824, 0.23201331, 0.15369977, 0.11308134]),\n",
       "  'train_ap': array([1., 1., 1., 1., 1.]),\n",
       "  'test_auc': array([0.62473118, 0.75177305, 0.6855792 , 0.61290323, 0.56501182]),\n",
       "  'train_auc': array([1., 1., 1., 1., 1.])},\n",
       " 0.1781403725005992,\n",
       " 0.6479996949592008)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForestRegressor\n",
    "model = XGBClassifier(booster='gbtree')\n",
    "estimator = BinarizeTargetClassifier(model)\n",
    "\n",
    "rval = rval_xgbc = cross_validate(estimator, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([78.1516099 , 78.51624084, 73.64381695, 74.016469  , 62.3948679 ]),\n",
       "  'score_time': array([0.22927213, 0.1422174 , 0.12280393, 0.14198899, 0.11951995]),\n",
       "  'test_ap': array([0.18876325, 0.46920738, 0.08357605, 0.18640097, 0.3403279 ]),\n",
       "  'train_ap': array([1.        , 0.9965505 , 0.99928876, 0.99315768, 0.99863272]),\n",
       "  'test_auc': array([0.49784946, 0.71276596, 0.45744681, 0.66451613, 0.61820331]),\n",
       "  'train_auc': array([1.        , 0.99963964, 0.99992793, 0.9992111 , 0.99985927])},\n",
       " 0.25365510902236943,\n",
       " 0.5901563334095935)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForestRegressor\n",
    "model = XGBRegressor(booster='dart')\n",
    "estimator = BinarizeTargetRegressor(model)\n",
    "\n",
    "rval = rval_xgbc = cross_validate(estimator, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guq/miniconda3/envs/python3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:700: UserWarning:\n",
      "\n",
      "A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "\n",
      "/Users/guq/miniconda3/envs/python3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:700: UserWarning:\n",
      "\n",
      "A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([54.3279388 , 54.78639698, 58.14463997, 58.99958086, 49.04657722]),\n",
       "  'score_time': array([0.21970987, 0.12079382, 0.11057305, 0.116395  , 0.09666681]),\n",
       "  'test_ap': array([0.1825592 , 0.20934824, 0.23201331, 0.15369977, 0.11308134]),\n",
       "  'train_ap': array([1., 1., 1., 1., 1.]),\n",
       "  'test_auc': array([0.62473118, 0.75177305, 0.6855792 , 0.61290323, 0.56501182]),\n",
       "  'train_auc': array([1., 1., 1., 1., 1.])},\n",
       " 0.1781403725005992,\n",
       " 0.6479996949592008)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForestRegressor\n",
    "model = XGBClassifier(booster='dart')\n",
    "estimator = BinarizeTargetClassifier(model)\n",
    "\n",
    "rval = rval_xgbc = cross_validate(estimator, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([26.35266781, 26.27872992, 25.77276421, 25.12663984, 22.47579813]),\n",
       "  'score_time': array([0.14111519, 0.12460303, 0.09760785, 0.11496401, 0.08929992]),\n",
       "  'test_ap': array([0.19652783, 0.17541398, 0.54640689, 0.29896941, 0.17979842]),\n",
       "  'train_ap': array([0.99932524, 0.99514322, 0.99579975, 0.9962882 , 0.99868421]),\n",
       "  'test_auc': array([0.60107527, 0.59456265, 0.77777778, 0.5655914 , 0.58628842]),\n",
       "  'train_auc': array([0.99992964, 0.9994955 , 0.99956757, 0.99960555, 0.99985927])},\n",
       " 0.27942330633236634,\n",
       " 0.6250591016548463)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForestRegressor\n",
    "model = XGBRegressor(booster='gblinear')\n",
    "estimator = BinarizeTargetRegressor(model)\n",
    "\n",
    "rval = rval_xgbc = cross_validate(estimator, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([24.78723407, 24.74860811, 19.673738  , 19.70348072, 17.64688706]),\n",
       "  'score_time': array([0.10551882, 0.08257294, 0.07710195, 0.07884502, 0.07354999]),\n",
       "  'test_ap': array([0.25236326, 0.27912091, 0.35086208, 0.25377759, 0.14262643]),\n",
       "  'train_ap': array([1., 1., 1., 1., 1.]),\n",
       "  'test_auc': array([0.74623656, 0.73758865, 0.71276596, 0.70537634, 0.58392435]),\n",
       "  'train_auc': array([1., 1., 1., 1., 1.])},\n",
       " 0.2557500560204116,\n",
       " 0.6971783726073363)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForestRegressor\n",
    "model = XGBClassifier(booster='gblinear')\n",
    "estimator = BinarizeTargetClassifier(model)\n",
    "\n",
    "rval = rval_xgbc = cross_validate(estimator, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([16.90042114, 16.46488619, 16.54236293, 14.97077203, 15.11325002]),\n",
       "  'score_time': array([0.00956583, 0.01592088, 0.00743699, 0.00809598, 0.00716376]),\n",
       "  'test_ap': array([0.1570016 , 0.14810019, 0.33751344, 0.28619806, 0.11887029]),\n",
       "  'train_ap': array([1., 1., 1., 1., 1.]),\n",
       "  'test_auc': array([0.55483871, 0.51536643, 0.76241135, 0.50860215, 0.46453901]),\n",
       "  'train_auc': array([1., 1., 1., 1., 1.])},\n",
       " 0.20953671522572775,\n",
       " 0.561151529017006)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForestRegressor\n",
    "model = svm.LinearSVR()\n",
    "estimator = BinarizeTargetRegressor(model)\n",
    "\n",
    "rval = rval_xgbc = cross_validate(estimator, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([1.73863626, 1.87055707, 1.59330297, 1.47868395, 1.28396702]),\n",
       "  'score_time': array([0.42028475, 0.51183677, 0.32850575, 0.26224804, 0.26199985]),\n",
       "  'test_ap': array([0.20222199, 0.11302112, 0.16017414, 0.29686041, 0.14140872]),\n",
       "  'train_ap': array([0.28641164, 0.32144943, 0.31205531, 0.33792667, 0.37808371]),\n",
       "  'test_auc': array([0.68172043, 0.49408983, 0.678487  , 0.5311828 , 0.5070922 ]),\n",
       "  'train_auc': array([0.63580073, 0.7045045 , 0.67120721, 0.70087437, 0.71882916])},\n",
       " 0.1827372746350011,\n",
       " 0.5785144513078625)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForestRegressor\n",
    "model = svm.SVR()\n",
    "estimator = BinarizeTargetRegressor(model)\n",
    "\n",
    "rval = rval_xgbc = cross_validate(estimator, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guq/miniconda3/envs/python3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:700: UserWarning:\n",
      "\n",
      "A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([3.58205414, 3.94731593, 4.23961806, 4.07637525, 2.50525331]),\n",
       "  'score_time': array([0.0103519 , 0.00686216, 0.01069283, 0.009197  , 0.00714993]),\n",
       "  'test_ap': array([0.1627808 , 0.22433335, 0.55330589, 0.30477076, 0.11665522]),\n",
       "  'train_ap': array([1., 1., 1., 1., 1.]),\n",
       "  'test_auc': array([0.57849462, 0.58392435, 0.80496454, 0.58494624, 0.43498818]),\n",
       "  'train_auc': array([1., 1., 1., 1., 1.])},\n",
       " 0.27236920317010826,\n",
       " 0.5974635857545947)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForestRegressor\n",
    "model = linear_model.LinearRegression()\n",
    "estimator = BinarizeTargetRegressor(model)\n",
    "\n",
    "rval = rval_xgbc = cross_validate(estimator, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([0.76888299, 0.767272  , 0.79688692, 0.79752707, 0.94955897]),\n",
       "  'score_time': array([0.00853682, 0.00872016, 0.01020217, 0.01008582, 0.00823402]),\n",
       "  'test_ap': array([0.16114061, 0.22433335, 0.55609063, 0.3046532 , 0.11637032]),\n",
       "  'train_ap': array([1., 1., 1., 1., 1.]),\n",
       "  'test_auc': array([0.57096774, 0.58392435, 0.80732861, 0.58387097, 0.43380615]),\n",
       "  'train_auc': array([1., 1., 1., 1., 1.])},\n",
       " 0.2725176225260262,\n",
       " 0.5959795622664531)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForestRegressor\n",
    "model = linear_model.Ridge()\n",
    "estimator = BinarizeTargetRegressor(model)\n",
    "\n",
    "rval = rval_xgbc = cross_validate(estimator, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([0.63219404, 0.63213992, 0.61962914, 0.6197722 , 0.55905485]),\n",
       "  'score_time': array([0.00810504, 0.00832486, 0.0084908 , 0.0083487 , 0.00580716]),\n",
       "  'test_ap': array([0.09708738, 0.08737864, 0.08737864, 0.09708738, 0.08737864]),\n",
       "  'train_ap': array([0.09223301, 0.08980583, 0.08980583, 0.09951456, 0.09223301]),\n",
       "  'test_auc': array([0.5, 0.5, 0.5, 0.5, 0.5]),\n",
       "  'train_auc': array([0.5, 0.5, 0.5, 0.5, 0.5])},\n",
       " 0.0912621359223301,\n",
       " 0.5)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForestRegressor\n",
    "model = linear_model.LassoLars()\n",
    "estimator = BinarizeTargetRegressor(model)\n",
    "\n",
    "rval = rval_xgbc = cross_validate(estimator, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([493.7193048 , 494.2635498 , 474.86757517, 474.83508897,\n",
       "         361.44782996]),\n",
       "  'score_time': array([0.23650002, 0.24748325, 0.45393896, 0.74201679, 0.23339796]),\n",
       "  'test_ap': array([0.22202179, 0.26082275, 0.26540851, 0.24967395, 0.14351668]),\n",
       "  'train_ap': array([1., 1., 1., 1., 1.]),\n",
       "  'test_auc': array([0.69032258, 0.65602837, 0.58865248, 0.58064516, 0.54728132]),\n",
       "  'train_auc': array([1., 1., 1., 1., 1.])},\n",
       " 0.22828873426373525,\n",
       " 0.6125859833752765)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_xgbc = BinarizeTargetClassifier(XGBClassifier(booster='gblinear'))\n",
    "li_xgbr = XGBRegressor(booster='gblinear')\n",
    "li_regr = linear_model.LinearRegression()\n",
    "dart_xgbr = XGBRegressor(booster='gbtree'))\n",
    "tree_xgbc = BinarizeTargetClassifier(XGBClassifier(booster='gbtree')\n",
    "ridge = BinarizeTargetRegressor(linear_model.Ridge())\n",
    "\n",
    "estimator = StackingCVRegressor(regressors=[li_xgbc, li_xgbr, li_regr, dart_xgbr], meta_regressor=ridge)\n",
    "rval = rval_xgbc = cross_validate(estimator, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([96.9130609 , 97.29991007, 96.83809209, 96.69504523, 90.05896711]),\n",
       "  'score_time': array([0.27100301, 0.25398421, 0.24240375, 0.25119376, 0.219244  ]),\n",
       "  'test_ap': array([0.19653881, 0.29207242, 0.45725215, 0.30045446, 0.13980685]),\n",
       "  'train_ap': array([1., 1., 1., 1., 1.]),\n",
       "  'test_auc': array([0.59462366, 0.65130024, 0.78486998, 0.57526882, 0.50118203]),\n",
       "  'train_auc': array([1., 1., 1., 1., 1.])},\n",
       " 0.27722493693512895,\n",
       " 0.6214489437962328)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_xgbc = BinarizeTargetClassifier(XGBClassifier(booster='gblinear'))\n",
    "li_xgbr = BinarizeTargetRegressor(XGBRegressor(booster='gblinear'))\n",
    "li_regr = BinarizeTargetRegressor(linear_model.LinearRegression())\n",
    "dart_xgbr = BinarizeTargetRegressor(XGBRegressor(booster='gbtree'))\n",
    "tree_xgbc = BinarizeTargetClassifier(XGBClassifier(booster='gbtree'))\n",
    "ridge = BinarizeTargetRegressor(linear_model.Ridge())\n",
    "\n",
    "estimator = StackingRegressor(regressors=[li_xgbc, li_xgbr, li_regr, dart_xgbr], meta_regressor=ridge)\n",
    "rval = rval_xgbc = cross_validate(estimator, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([191.8877182 , 190.62075114, 185.74918485, 185.33830881,\n",
       "         122.59476876]),\n",
       "  'score_time': array([0.37178493, 0.1400919 , 0.1320312 , 0.31230688, 0.12863994]),\n",
       "  'test_ap': array([0.20350183, 0.18619149, 0.41742316, 0.26587717, 0.14943181]),\n",
       "  'train_ap': array([1., 1., 1., 1., 1.]),\n",
       "  'test_auc': array([0.62150538, 0.60756501, 0.76359338, 0.57741935, 0.56973995]),\n",
       "  'train_auc': array([1., 1., 1., 1., 1.])},\n",
       " 0.2444850923755666,\n",
       " 0.627964615267292)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_xgbc = BinarizeTargetClassifier(XGBClassifier(booster='gblinear'))\n",
    "li_xgbr = BinarizeTargetRegressor(XGBRegressor(booster='gblinear'))\n",
    "\n",
    "\n",
    "\n",
    "estimator = StackingCVRegressor(regressors=[li_xgbc, li_xgbr], meta_regressor=li_xgbc, cv=cv)\n",
    "rval = rval_xgbc = cross_validate(estimator, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([37.99209094, 38.07731581, 38.842978  , 38.91868496, 35.52078199]),\n",
       "  'score_time': array([0.13653493, 0.13990808, 0.14602399, 0.16231012, 0.12697101]),\n",
       "  'test_ap': array([0.24110587, 0.25961513, 0.36868437, 0.23965035, 0.14482645]),\n",
       "  'train_ap': array([1., 1., 1., 1., 1.]),\n",
       "  'test_auc': array([0.71075269, 0.6678487 , 0.75295508, 0.63978495, 0.55673759]),\n",
       "  'train_auc': array([1., 1., 1., 1., 1.])},\n",
       " 0.2507764345339895,\n",
       " 0.6656158011133989)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_xgbc = BinarizeTargetClassifier(XGBClassifier(booster='gblinear'))\n",
    "li_xgbr = BinarizeTargetRegressor(XGBRegressor(booster='gblinear'))\n",
    "\n",
    "\n",
    "\n",
    "estimator = StackingRegressor(regressors=[li_xgbc, li_xgbr], meta_regressor=li_xgbc)\n",
    "rval = rval_xgbc = cross_validate(estimator, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([38.89744902, 38.96073127, 39.31595802, 39.38810515, 35.56646299]),\n",
       "  'score_time': array([0.14418197, 0.14413476, 0.143852  , 0.16138387, 0.12565899]),\n",
       "  'test_ap': array([0.2279173 , 0.25644716, 0.38504068, 0.24236346, 0.14548832]),\n",
       "  'train_ap': array([1., 1., 1., 1., 1.]),\n",
       "  'test_auc': array([0.66666667, 0.63356974, 0.75531915, 0.61935484, 0.55910165]),\n",
       "  'train_auc': array([1., 1., 1., 1., 1.])},\n",
       " 0.2514513839759419,\n",
       " 0.6468024098223136)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_xgbc = BinarizeTargetClassifier(XGBClassifier(booster='gblinear'))\n",
    "li_xgbr = BinarizeTargetRegressor(XGBRegressor(booster='gblinear'))\n",
    "\n",
    "\n",
    "\n",
    "estimator = StackingRegressor(regressors=[li_xgbc, li_xgbr], meta_regressor=li_xgbr)\n",
    "rval = rval_xgbc = cross_validate(estimator, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([39.24416208, 39.20689201, 41.59895134, 40.93226004, 35.78442383]),\n",
       "  'score_time': array([0.15409493, 0.15156507, 0.14003086, 0.13279796, 0.13306808]),\n",
       "  'test_ap': array([0.19652783, 0.17541398, 0.54640689, 0.29896941, 0.17979842]),\n",
       "  'train_ap': array([0.99799169, 0.99357611, 0.99138715, 0.99573449, 0.99589245]),\n",
       "  'test_auc': array([0.60107527, 0.59456265, 0.77777778, 0.5655914 , 0.58628842]),\n",
       "  'train_auc': array([0.99978891, 0.99935135, 0.99913514, 0.99953981, 0.99957782])},\n",
       " 0.27942330633236634,\n",
       " 0.6250591016548463)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_xgbc = BinarizeTargetClassifier(XGBClassifier(booster='gblinear'))\n",
    "li_xgbr = BinarizeTargetRegressor(XGBRegressor(booster='gblinear'))\n",
    "\n",
    "\n",
    "\n",
    "estimator = StackingRegressor(regressors=[li_xgbc, li_xgbr], meta_regressor=li_regr)\n",
    "rval = rval_xgbc = cross_validate(estimator, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([38.75615072, 38.71743274, 39.71388292, 39.61611295, 35.56258488]),\n",
       "  'score_time': array([0.14720821, 0.14346433, 0.16296315, 0.17165327, 0.12340307]),\n",
       "  'test_ap': array([0.19652783, 0.17541398, 0.54640689, 0.29896941, 0.17979842]),\n",
       "  'train_ap': array([0.99799169, 0.99357611, 0.99138715, 0.99573449, 0.99589245]),\n",
       "  'test_auc': array([0.60107527, 0.59456265, 0.77777778, 0.5655914 , 0.58628842]),\n",
       "  'train_auc': array([0.99978891, 0.99935135, 0.99913514, 0.99953981, 0.99957782])},\n",
       " 0.27942330633236634,\n",
       " 0.6250591016548463)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_xgbc = BinarizeTargetClassifier(XGBClassifier(booster='gblinear'))\n",
    "li_xgbr = BinarizeTargetRegressor(XGBRegressor(booster='gblinear'))\n",
    "\n",
    "\n",
    "\n",
    "estimator = StackingRegressor(regressors=[li_xgbr, li_xgbc], meta_regressor=li_regr)\n",
    "rval = rval_xgbc = cross_validate(estimator, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([39.40429688, 39.24081731, 40.81403899, 40.93233109, 36.58354902]),\n",
       "  'score_time': array([0.18129921, 0.15313983, 0.14315319, 0.15432191, 0.13195682]),\n",
       "  'test_ap': array([0.20160965, 0.2123033 , 0.4738413 , 0.26515902, 0.16573177]),\n",
       "  'train_ap': array([1., 1., 1., 1., 1.]),\n",
       "  'test_auc': array([0.61182796, 0.60756501, 0.76832151, 0.56989247, 0.57683215]),\n",
       "  'train_auc': array([1., 1., 1., 1., 1.])},\n",
       " 0.2637290092721102,\n",
       " 0.6268878212460917)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_xgbc = BinarizeTargetClassifier(XGBClassifier(booster='gblinear'))\n",
    "li_xgbr = BinarizeTargetRegressor(XGBRegressor(booster='gblinear'))\n",
    "\n",
    "svr = BinarizeTargetRegressor(svm.SVR())\n",
    "\n",
    "estimator = StackingRegressor(regressors=[li_xgbr, li_xgbc], meta_regressor=svr)\n",
    "rval = rval_xgbc = cross_validate(estimator, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guq/miniconda3/envs/python3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingRegressor(meta_regressor=BinarizeTargetRegressor(less_is_positive=True,\n",
       "            regressor=LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
       "     intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "     random_state=None, tol=0.0001, verbose=0),\n",
       "            value=None, z_score=-1),\n",
       "         refit=True,\n",
       "         regressors=[XGBRegressor(base_score=0.5, booster='gblinear', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, importance_type='gain',\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "       nthread=None, objective='..., reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1)],\n",
       "         store_train_meta_features=True, use_features_in_secondary=False,\n",
       "         verbose=0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_xgbr = XGBRegressor(booster='gblinear')\n",
    "dart_xgbr = XGBRegressor(booster='dart')\n",
    "\n",
    "li_svr = BinarizeTargetRegressor(svm.LinearSVR())\n",
    "\n",
    "estimator = StackingRegressor(regressors=[li_xgbr, dart_xgbr], meta_regressor=li_svr, store_train_meta_features=True)\n",
    "estimator.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([124.69434381, 125.30925369, 133.40533686, 133.12793589,\n",
       "          92.99674702]),\n",
       "  'score_time': array([0.15308809, 0.18115306, 0.14425492, 0.32195592, 0.16678977]),\n",
       "  'test_ap': array([0.09960013, 0.15663279, 0.16775422, 0.15215827, 0.14618425]),\n",
       "  'train_ap': array([0.19825039, 0.13646325, 0.14589986, 0.18380555, 0.17153999]),\n",
       "  'test_auc': array([0.49784946, 0.53546099, 0.51891253, 0.58064516, 0.6713948 ]),\n",
       "  'train_auc': array([0.66260906, 0.61167568, 0.63445045, 0.63572415, 0.58858711])},\n",
       " 0.14446593288746462,\n",
       " 0.5608525890337833)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_xgbr = XGBRegressor(booster='gblinear')\n",
    "dart_xgbr = XGBRegressor(booster='dart')\n",
    "\n",
    "b_li_xgbr = BinarizeTargetRegressor(li_xgbr)\n",
    "\n",
    "estimator = StackingCVRegressor(regressors=[li_xgbr], meta_regressor=b_li_xgbr, use_features_in_secondary=True, cv=cv)\n",
    "rval = rval_xgbc = cross_validate(estimator, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([311.69929695, 310.30883503, 287.00330901, 286.14769006,\n",
       "         196.48079991]),\n",
       "  'score_time': array([0.37614608, 0.17628908, 0.18121386, 0.3412571 , 0.19308019]),\n",
       "  'test_ap': array([0.19652783, 0.17541398, 0.54640689, 0.29896941, 0.17979842]),\n",
       "  'train_ap': array([0.99932524, 0.99514322, 0.99579975, 0.9962882 , 0.99868421]),\n",
       "  'test_auc': array([0.60107527, 0.59456265, 0.77777778, 0.5655914 , 0.58628842]),\n",
       "  'train_auc': array([0.99992964, 0.9994955 , 0.99956757, 0.99960555, 0.99985927])},\n",
       " 0.27942330633236634,\n",
       " 0.6250591016548463)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_xgbr = XGBRegressor(booster='gblinear')\n",
    "dart_xgbr = XGBRegressor(booster='dart')\n",
    "\n",
    "b_li_xgbr = BinarizeTargetRegressor(li_xgbr)\n",
    "\n",
    "estimator = StackingCVRegressor(regressors=[dart_xgbr], meta_regressor=b_li_xgbr, use_features_in_secondary=True, cv=cv)\n",
    "rval = rval_xgbc = cross_validate(estimator, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([136.05898094, 136.12344909, 128.66250396, 128.56200123,\n",
       "          84.30865002]),\n",
       "  'score_time': array([0.15638518, 0.16479206, 0.22243094, 0.22582483, 0.14675403]),\n",
       "  'test_ap': array([0.09960628, 0.15651334, 0.16701266, 0.15190823, 0.14657013]),\n",
       "  'train_ap': array([0.19796009, 0.13624807, 0.14594732, 0.18203343, 0.17135979]),\n",
       "  'test_auc': array([0.49784946, 0.53427896, 0.51654846, 0.57849462, 0.67375887]),\n",
       "  'train_auc': array([0.66225725, 0.61117117, 0.63466667, 0.6348695 , 0.58830566])},\n",
       " 0.14432212846543951,\n",
       " 0.5601860748875161)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_xgbr = XGBRegressor(booster='gblinear')\n",
    "li_xgbc = BinarizeTargetClassifier(XGBClassifier(booster='gblinear'))\n",
    "\n",
    "b_li_xgbr = BinarizeTargetRegressor(li_xgbr)\n",
    "\n",
    "estimator = StackingCVRegressor(regressors=[li_xgbc], meta_regressor=b_li_xgbr, use_features_in_secondary=True, cv=cv)\n",
    "rval = rval_xgbc = cross_validate(estimator, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([39.61985326, 39.70125604, 39.80138016, 39.68585801, 35.44212008]),\n",
       "  'score_time': array([0.143152  , 0.15950108, 0.14376307, 0.1465857 , 0.12894583]),\n",
       "  'test_ap': array([0.23996342, 0.26059812, 0.3677766 , 0.24239712, 0.14467946]),\n",
       "  'train_ap': array([1., 1., 1., 1., 1.]),\n",
       "  'test_auc': array([0.71290323, 0.6749409 , 0.75059102, 0.64516129, 0.55437352]),\n",
       "  'train_auc': array([1., 1., 1., 1., 1.])},\n",
       " 0.25108294316947316,\n",
       " 0.6675939906962556)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_xgbr = XGBRegressor(booster='gblinear')\n",
    "li_xgbc = BinarizeTargetClassifier(XGBClassifier(booster='gblinear'))\n",
    "\n",
    "logistic = BinarizeTargetClassifier(linear_model.LogisticRegression(random_state=10))\n",
    "\n",
    "estimator = StackingRegressor(regressors=[li_xgbc, b_li_xgbr], meta_regressor=logistic)\n",
    "rval = rval_xgbc = cross_validate(estimator, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([46.16073012, 46.32835817, 44.60787392, 44.5616641 , 35.26880884]),\n",
       "  'score_time': array([0.23214793, 0.15381193, 0.14202785, 0.14490581, 0.13124299]),\n",
       "  'test_ap': array([0.20155797, 0.14340511, 0.21885522, 0.2148291 , 0.12292945]),\n",
       "  'train_ap': array([1., 1., 1., 1., 1.]),\n",
       "  'test_auc': array([0.71827957, 0.59869976, 0.67257683, 0.58924731, 0.55141844]),\n",
       "  'train_auc': array([1., 1., 1., 1., 1.])},\n",
       " 0.18031536840502105,\n",
       " 0.6260443834362847)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_xgbr = XGBRegressor(booster='gblinear')\n",
    "li_xgbc = BinarizeTargetClassifier(XGBClassifier(booster='gblinear'))\n",
    "\n",
    "tree_xgbc = BinarizeTargetClassifier(XGBClassifier())\n",
    "\n",
    "estimator = StackingRegressor(regressors=[li_xgbc, b_li_xgbr], meta_regressor=tree_xgbc)\n",
    "rval = rval_xgbc = cross_validate(estimator, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([0.87585616, 0.87273693, 0.81873202, 0.8245759 , 0.70295906]),\n",
       "  'score_time': array([0.01136398, 0.01154304, 0.00921082, 0.00909805, 0.00841069]),\n",
       "  'test_ap': array([0.15505833, 0.43227028, 0.4143363 , 0.3067487 , 0.1697656 ]),\n",
       "  'train_ap': array([0.52671955, 0.52214137, 0.50793002, 0.50172871, 0.58561999]),\n",
       "  'test_auc': array([0.6688172 , 0.82269504, 0.64893617, 0.73225806, 0.643026  ]),\n",
       "  'train_auc': array([0.83528005, 0.85585586, 0.85772973, 0.84530932, 0.87904588])},\n",
       " 0.2956358397947346,\n",
       " 0.703146495843819)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=100)\n",
    "pipe = Pipeline([('kbest', kbest), ('est', XGBClassifier(booster='gblinear'))])\n",
    "\n",
    "estimator = BinarizeTargetClassifier(pipe)\n",
    "\n",
    "\n",
    "#estimator = StackingRegressor(regressors=[li_xgbc, b_li_xgbr], meta_regressor=tree_xgbc)\n",
    "rval = rval_xgbc = cross_validate(estimator, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([0.82664585, 0.82316613, 1.03288221, 1.00101972, 0.73297596]),\n",
       "  'score_time': array([0.00999093, 0.00954771, 0.01163602, 0.0094161 , 0.00898194]),\n",
       "  'test_ap': array([0.15640674, 0.2224037 , 0.11251846, 0.29284852, 0.17181898]),\n",
       "  'train_ap': array([0.53791992, 0.44624182, 0.46128298, 0.50887466, 0.44218562]),\n",
       "  'test_auc': array([0.60537634, 0.60165485, 0.5177305 , 0.51935484, 0.65130024]),\n",
       "  'train_auc': array([0.82620321, 0.78724324, 0.84079279, 0.84636119, 0.82233324])},\n",
       " 0.19119927941731876,\n",
       " 0.5790833523983834)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif, f_regression\n",
    "\n",
    "kbest = SelectKBest(score_func=f_regression, k=200)\n",
    "pipe = Pipeline([('kbest', kbest), ('est', XGBRegressor(booster='gblinear'))])\n",
    "\n",
    "estimator = BinarizeTargetRegressor(pipe)\n",
    "\n",
    "\n",
    "#estimator = StackingRegressor(regressors=[li_xgbc, b_li_xgbr], meta_regressor=tree_xgbc)\n",
    "rval = rval_xgbc = cross_validate(estimator, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([0.84537888, 0.84544516, 0.82959485, 0.82854795, 0.83944082,\n",
       "         0.84481311, 0.85772014, 0.85639191, 0.87500691, 0.86388302,\n",
       "         0.90355682, 0.90314007, 0.84371805, 0.84578991, 0.85362005,\n",
       "         0.855304  , 0.85172606, 0.84939003, 0.83908701, 0.84570098,\n",
       "         0.86185503, 0.84546089, 0.84683514, 0.85004997, 0.84591699,\n",
       "         0.84661913, 0.87669396, 0.87529325, 0.86442113, 0.86286902,\n",
       "         0.85207891, 0.86170506, 0.94543314, 0.95135903, 1.018857  ,\n",
       "         1.04474497, 1.03684878, 1.04905319, 0.99194479, 1.02684999]),\n",
       "  'score_time': array([0.00786304, 0.0074501 , 0.00714207, 0.00764298, 0.00734377,\n",
       "         0.00781894, 0.00692606, 0.00716019, 0.00788927, 0.00710702,\n",
       "         0.00693035, 0.00707579, 0.00713992, 0.00692606, 0.00699687,\n",
       "         0.00678015, 0.007406  , 0.00706196, 0.00738883, 0.00816894,\n",
       "         0.01022506, 0.00951004, 0.00713682, 0.00715613, 0.00705218,\n",
       "         0.00702691, 0.00693202, 0.00685191, 0.00696993, 0.00716114,\n",
       "         0.00667906, 0.00779104, 0.00776076, 0.00738811, 0.00647497,\n",
       "         0.00636101, 0.00637913, 0.00664091, 0.00675726, 0.00642705]),\n",
       "  'test_ap': array([0.13723923, 0.55716335, 0.37384259, 0.19606171, 0.34529115,\n",
       "         0.58781609, 0.22157895, 0.11258426, 0.13858308, 0.38596491,\n",
       "         0.13413092, 0.275     , 0.44710526, 0.36718629, 0.19270833,\n",
       "         0.19169427, 0.20247008, 0.38833333, 0.32467228, 0.55846154,\n",
       "         0.30636769, 0.47211022, 0.33207071, 0.32574916, 0.39624265,\n",
       "         0.31135321, 0.39472958, 0.52180964, 0.51010101, 0.10809889,\n",
       "         0.46666667, 0.19014493, 0.58465608, 0.44216802, 0.1605766 ,\n",
       "         0.2847619 , 0.34651421, 0.38493125, 0.25359983, 0.230713  ]),\n",
       "  'train_ap': array([0.52448988, 0.44246403, 0.49515161, 0.51377019, 0.46590669,\n",
       "         0.4375462 , 0.46561367, 0.49378977, 0.51143083, 0.48918109,\n",
       "         0.47434815, 0.46295124, 0.49191791, 0.46606887, 0.45102103,\n",
       "         0.47412992, 0.50419313, 0.50470546, 0.47437503, 0.46720699,\n",
       "         0.50564207, 0.46203689, 0.49863193, 0.46325106, 0.44781024,\n",
       "         0.50871693, 0.52410452, 0.50151452, 0.45021569, 0.51519116,\n",
       "         0.47929733, 0.47791433, 0.49008369, 0.51567852, 0.45719352,\n",
       "         0.46494047, 0.42834246, 0.48932236, 0.50364624, 0.5080091 ]),\n",
       "  'test_auc': array([0.59148936, 0.77446809, 0.734375  , 0.71489362, 0.625     ,\n",
       "         0.8       , 0.72173913, 0.59574468, 0.59130435, 0.83913043,\n",
       "         0.49361702, 0.80729167, 0.76170213, 0.72916667, 0.765625  ,\n",
       "         0.65217391, 0.76086957, 0.85217391, 0.67391304, 0.83478261,\n",
       "         0.61702128, 0.703125  , 0.859375  , 0.64680851, 0.8       ,\n",
       "         0.60434783, 0.8037037 , 0.74782609, 0.86956522, 0.57978723,\n",
       "         0.66666667, 0.73617021, 0.87659574, 0.73191489, 0.65531915,\n",
       "         0.82173913, 0.69565217, 0.71276596, 0.69565217, 0.70744681]),\n",
       "  'train_auc': array([0.85301436, 0.8323719 , 0.84174972, 0.84557032, 0.8341251 ,\n",
       "         0.81888528, 0.83636049, 0.8332873 , 0.85310475, 0.83024852,\n",
       "         0.8401199 , 0.82694265, 0.84221242, 0.82343626, 0.818516  ,\n",
       "         0.82489177, 0.82932803, 0.83683142, 0.83638005, 0.83653347,\n",
       "         0.85348515, 0.83067553, 0.83660022, 0.82637845, 0.82279505,\n",
       "         0.85082374, 0.8416372 , 0.843884  , 0.82743506, 0.84215368,\n",
       "         0.85426357, 0.83105999, 0.83470119, 0.8448752 , 0.83078837,\n",
       "         0.82196321, 0.82661593, 0.83914268, 0.82895022, 0.84157322])},\n",
       " 0.3290313212263903,\n",
       " 0.721273573744304)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif, f_regression\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=100)\n",
    "pipe = Pipeline([('kbest', kbest), ('est', XGBClassifier(booster='gblinear'))])\n",
    "\n",
    "estimator = BinarizeTargetClassifier(pipe)\n",
    "cv2 = RepeatedOrderedKFold(n_splits=10, n_repeats=4)\n",
    "\n",
    "#estimator = StackingRegressor(regressors=[li_xgbc, b_li_xgbr], meta_regressor=tree_xgbc)\n",
    "rval = rval_xgbc = cross_validate(estimator, X, y, cv=cv2, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([ 78.91654301,  79.32998705,  76.88240886,  78.37418389,\n",
       "          75.95218587,  77.74600387,  88.66994882,  89.95894694,\n",
       "         101.47562003, 102.8608861 ]),\n",
       "  'score_time': array([0.00601912, 0.00611782, 0.00633407, 0.00654531, 0.00606513,\n",
       "         0.00589108, 0.00564003, 0.00640726, 0.00574088, 0.0054481 ]),\n",
       "  'test_ap': array([0.33371594, 0.22287218, 0.25302036, 0.24092419, 0.52846154,\n",
       "         0.16618687, 0.11347222, 0.63333333, 0.40332675, 0.16696429]),\n",
       "  'train_ap': array([0.46568576, 0.40693022, 0.4123278 , 0.39498861, 0.36924386,\n",
       "         0.43190332, 0.41763564, 0.39063657, 0.37261556, 0.39192393]),\n",
       "  'test_auc': array([0.62318841, 0.59574468, 0.77446809, 0.70638298, 0.80851064,\n",
       "         0.61304348, 0.52608696, 0.92553191, 0.84574468, 0.7287234 ]),\n",
       "  'train_auc': array([0.82973621, 0.82545021, 0.80393134, 0.79894808, 0.77457301,\n",
       "         0.82182352, 0.80991875, 0.79541864, 0.79304897, 0.78966373])},\n",
       " 0.30622776594284973,\n",
       " 0.7147425223558435)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif, f_regression, chi2, mutual_info_classif\n",
    "\n",
    "kbest = SelectKBest(score_func=mutual_info_classif, k=100)\n",
    "pipe = Pipeline([('kbest', kbest), ('est', XGBClassifier(booster='gblinear'))])\n",
    "\n",
    "estimator = BinarizeTargetClassifier(pipe)\n",
    "cv2 = OrderedKFold(n_splits=10)\n",
    "\n",
    "#estimator = StackingRegressor(regressors=[li_xgbc, b_li_xgbr], meta_regressor=tree_xgbc)\n",
    "rval = rval_xgbc = cross_validate(estimator, X, y, cv=cv2, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([0.80747819, 0.80850697, 0.96671104, 0.9637239 , 0.88724303]),\n",
       "  'score_time': array([0.00885892, 0.00903296, 0.01237369, 0.01175904, 0.00784993]),\n",
       "  'test_ap': array([0.15505833, 0.43227028, 0.4143363 , 0.3067487 , 0.1697656 ]),\n",
       "  'train_ap': array([0.52671955, 0.52214137, 0.50793002, 0.50172871, 0.58561999]),\n",
       "  'test_auc': array([0.6688172 , 0.82269504, 0.64893617, 0.73225806, 0.643026  ]),\n",
       "  'train_auc': array([0.83528005, 0.85585586, 0.85772973, 0.84530932, 0.87904588])},\n",
       " 0.2956358397947346,\n",
       " 0.703146495843819)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif, f_regression, chi2, mutual_info_classif\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=100)\n",
    "pipe = Pipeline([('kbest', kbest), ('est', XGBClassifier(booster='gblinear'))])\n",
    "\n",
    "estimator = BinarizeTargetClassifier(pipe)\n",
    "\n",
    "#estimator = StackingRegressor(regressors=[li_xgbc, b_li_xgbr], meta_regressor=tree_xgbc)\n",
    "rval = rval_xgbc = cross_validate(estimator, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([0.89957118, 0.89838886, 0.77832007, 0.78742003, 0.71401811]),\n",
       "  'score_time': array([0.0121398 , 0.01203823, 0.01151299, 0.01260591, 0.01006794]),\n",
       "  'test_ap': array([0.15505833, 0.43227028, 0.4143363 , 0.3067487 , 0.1697656 ]),\n",
       "  'train_ap': array([0.52671955, 0.52214137, 0.50793002, 0.50172871, 0.58561999]),\n",
       "  'test_auc': array([0.6688172 , 0.82269504, 0.64893617, 0.73225806, 0.643026  ]),\n",
       "  'train_auc': array([0.83528005, 0.85585586, 0.85772973, 0.84530932, 0.87904588])},\n",
       " 0.2956358397947346,\n",
       " 0.703146495843819)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif, f_regression, chi2, mutual_info_classif\n",
    "\n",
    "kbest = BinarizeTargetTransformer(SelectKBest(score_func=f_classif, k=100))\n",
    "b_li_xgbc = BinarizeTargetClassifier(XGBClassifier(booster='gblinear'))\n",
    "pipe = Pipeline([('kbest', kbest), ('est', b_li_xgbc)])\n",
    "\n",
    "#estimator = BinarizeTargetClassifier(pipe)\n",
    "\n",
    "#estimator = StackingRegressor(regressors=[li_xgbc, b_li_xgbr], meta_regressor=tree_xgbc)\n",
    "rval = rval_xgbc = cross_validate(pipe, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([0.86327505, 0.8614881 , 0.86848092, 0.86655998, 0.85222197,\n",
       "         0.85401702, 0.86022305, 0.85501313, 0.88761592, 0.88791919]),\n",
       "  'score_time': array([0.00802898, 0.00774574, 0.00735736, 0.00696325, 0.00735092,\n",
       "         0.00693798, 0.00852895, 0.00747371, 0.00730991, 0.00702381]),\n",
       "  'test_ap': array([0.39183087, 0.13152668, 0.39108392, 0.38039216, 0.37063492,\n",
       "         0.17760132, 0.12175806, 0.70486111, 0.31822344, 0.13142691]),\n",
       "  'train_ap': array([0.40377606, 0.35739313, 0.37260576, 0.37157477, 0.32977998,\n",
       "         0.3569796 , 0.38050912, 0.32173461, 0.3420138 , 0.37496741]),\n",
       "  'test_auc': array([0.70652174, 0.57021277, 0.83829787, 0.77021277, 0.8212766 ,\n",
       "         0.63913043, 0.56086957, 0.94680851, 0.81914894, 0.64361702]),\n",
       "  'train_auc': array([0.79136691, 0.78156867, 0.77956811, 0.7864495 , 0.77680692,\n",
       "         0.79129993, 0.79361318, 0.77524825, 0.77025502, 0.78390882])},\n",
       " 0.31193393945075576,\n",
       " 0.7316096207215541)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif, f_regression, chi2, mutual_info_classif\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, Normalizer\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=100)\n",
    "scaler = Normalizer(norm='l2')\n",
    "pipe = Pipeline([('kbest', kbest), ('scaler', scaler), ('est', XGBClassifier(booster='gblinear'))])\n",
    "\n",
    "estimator = BinarizeTargetClassifier(pipe)\n",
    "cv2 = OrderedKFold(n_splits=10)\n",
    "\n",
    "#estimator = StackingRegressor(regressors=[li_xgbc, b_li_xgbr], meta_regressor=tree_xgbc)\n",
    "rval = rval_xgbc = cross_validate(estimator, X, y, cv=cv2, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([1.39193296, 1.43207622, 1.63655019, 1.67825317, 1.43408418]),\n",
       "  'score_time': array([0.01181793, 0.018718  , 0.01180506, 0.01198483, 0.0103879 ]),\n",
       "  'test_ap': array([0.07976097, 0.07471882, 0.14323093, 0.09130802, 0.06855856]),\n",
       "  'train_ap': array([0.05569102, 0.05745081, 0.05488744, 0.05887507, 0.06037589]),\n",
       "  'test_auc': array([0.36612903, 0.29787234, 0.58628842, 0.44462366, 0.3179669 ]),\n",
       "  'train_auc': array([0.20071067, 0.2525045 , 0.21466667, 0.18394583, 0.25738812])},\n",
       " 0.09151545745812409,\n",
       " 0.40257606954930214)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif, f_regression, chi2, mutual_info_classif\n",
    "\n",
    "kbest = BinarizeTargetTransformer(SelectKBest(score_func=f_classif, k=100))\n",
    "li_xgbc = XGBClassifier(booster='gblinear')\n",
    "b_li_xgbc = BinarizeTargetClassifier(li_xgbc)\n",
    "tree_xgbr = XGBClassifier(booster='gbtree')\n",
    "dart_xgbr = XGBClassifier(booster='dart')\n",
    "li_xgbr = XGBRegressor(booster='gblinear')\n",
    "\n",
    "logistic = linear_model.LogisticRegression()\n",
    "stacking = StackingCVRegressor(regressors=[li_xgbr], meta_regressor=b_li_xgbc, cv=cv, use_features_in_secondary=False)\n",
    "\n",
    "pipe = Pipeline([('kbest', kbest), ('est', BinarizeTargetRegressor(stacking))])\n",
    "\n",
    "rval = rval_xgbc = cross_validate(pipe, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([1.88816905, 1.8882103 , 1.92051101, 1.92165804, 1.40746522]),\n",
       "  'score_time': array([0.01359391, 0.01357794, 0.01386905, 0.01347208, 0.01095986]),\n",
       "  'test_ap': array([0.15505833, 0.43227028, 0.4143363 , 0.3067487 , 0.1697656 ]),\n",
       "  'train_ap': array([0.52671955, 0.52214137, 0.50793002, 0.50172871, 0.58561999]),\n",
       "  'test_auc': array([0.6688172 , 0.82269504, 0.64893617, 0.73225806, 0.643026  ]),\n",
       "  'train_auc': array([0.83528005, 0.85585586, 0.85772973, 0.84530932, 0.87904588])},\n",
       " 0.2956358397947346,\n",
       " 0.703146495843819)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif, f_regression, chi2, mutual_info_classif\n",
    "\n",
    "kbest = BinarizeTargetTransformer(SelectKBest(score_func=f_classif, k=100))\n",
    "li_xgbc = XGBClassifier(booster='gblinear')\n",
    "b_li_xgbc = BinarizeTargetClassifier(li_xgbc)\n",
    "tree_xgbr = XGBClassifier(booster='gbtree')\n",
    "dart_xgbr = XGBClassifier(booster='dart')\n",
    "li_xgbr = XGBRegressor(booster='gblinear')\n",
    "\n",
    "logistic = linear_model.LogisticRegression()\n",
    "svr = svm.SVR()\n",
    "\n",
    "cv2 = OrderedKFold(n_splits=10)\n",
    "\n",
    "stacking = StackingCVClassifier(classifiers=[li_xgbc], meta_classifier=li_xgbc, cv=cv2, use_features_in_secondary=True)\n",
    "\n",
    "pipe = Pipeline([('kbest', kbest), ('est', BinarizeTargetClassifier(stacking))])\n",
    "\n",
    "rval = rval_xgbc = cross_validate(pipe, X, y, cv=cv, scoring=scoring, n_jobs=2)\n",
    "rval, np.mean(rval['test_ap']), np.mean(rval['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
